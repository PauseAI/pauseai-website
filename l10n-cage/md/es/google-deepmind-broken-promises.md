---
title: Las promesas incumplidas de Google DeepMind
slug: google-deepmind-promesas-incumplidas
description: La empresa de inteligencia artificial Google DeepMind ha incumplido las promesas que hizo al público.
date: 2025-06-30T12:36:00.000Z
---

La empresa de inteligencia artificial Google DeepMind ha incumplido sus compromisos con los gobiernos y el público, establecidos en los [Compromisos de seguridad de IA de vanguardia](https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024), con el lanzamiento de Gemini 2.5 Pro.

### Cumbres de seguridad de IA {#ai-safety-summits}

- En 2023, el Reino Unido organizó [la primera Cumbre de seguridad de IA](https://www.gov.uk/government/topical-events/ai-safety-summit-2023) en Bletchley Park, reuniendo a gobiernos y desarrolladores de IA para discutir la seguridad de la IA por primera vez.
- En 2024, el Reino Unido coorganizó [la Cumbre de IA de Seúl](https://www.gov.uk/government/topical-events/ai-seoul-summit-2024). Las empresas tecnológicas, incluyendo Google, firmaron los [Compromisos de seguridad de IA de vanguardia](https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024), estableciendo un enfoque para desarrollar sistemas de IA de vanguardia de manera más segura.

### Los Compromisos de seguridad de IA de vanguardia {#the-frontier-ai-safety-commitments}

Los compromisos establecen un marco inicial para que los desarrolladores de IA tomen medidas preventivas básicas contra los riesgos crecientes de los modelos de IA de vanguardia. Eran compromisos voluntarios, no obligatorios en ninguna jurisdicción.

Dos de los compromisos son los siguientes:

- “I: Evaluar los riesgos planteados por sus modelos de vanguardia [...] antes de desplegar ese modelo. También deben considerar los resultados de [...] evaluaciones externas según sea apropiado”.
- “VIII: Explicar cómo, si es que lo hacen, los actores externos, como los gobiernos [...], están involucrados en el proceso de evaluar los riesgos de sus modelos de IA”.

Google ha ignorado efectivamente estos compromisos en el lanzamiento de Gemini 2.5 Pro, estableciendo un precedente peligroso para futuros modelos.

Consideramos que deben ser responsabilizados por este incumplimiento para mantener la legitimidad de las Cumbres internacionales de seguridad de IA y facilitar la aprobación de futuras regulaciones de IA.

### Cronología y detalles de la violación de Google {#timeline-and-details-of-googles-violation}

#### 25 de marzo de 2025 {#25-march-2025}

- [Gemini 2.5 Pro Experimental](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/) se vuelve disponible para que cualquiera acceda de forma gratuita. Es posiblemente el modelo de IA más avanzado lanzado por cualquier empresa en este momento.
- [No se publica información](https://fortune.com/2025/04/09/google-gemini-2-5-pro-missing-model-card-in-apparent-violation-of-ai-safety-promises-to-us-government-international-bodies/) sobre pruebas de seguridad.

#### 3 de abril de 2025 {#3-april-2025}

- El jefe de producto de Gemini de Google [le dice a TechCrunch](https://techcrunch.com/2025/04/03/google-is-shipping-gemini-models-faster-than-its-ai-safety-reports/) que la empresa no ha publicado una 'ficha de modelo' (es decir, informe de seguridad) para Gemini 2.5 Pro "porque considera que el modelo es un lanzamiento 'experimental'".

#### 9 de abril de 2025 {#9-april-2025}

- [En correspondencia con la revista Fortune](https://fortune.com/2025/04/09/google-gemini-2-5-pro-missing-model-card-in-apparent-violation-of-ai-safety-promises-to-us-government-international-bodies), Google no responde a "preguntas directas" sobre la participación del Instituto de Seguridad de IA del Reino Unido en el proceso de prueba para Gemini 2.5 Pro. Sin embargo, un portavoz de Google dice que el modelo ha pasado por pruebas previas al lanzamiento.

#### 16 de abril de 2025 {#16-april-2025}

- Gemini 2.5 Pro Preview ahora está disponible (esencialmente el mismo que el modelo Experimental).
- Google publica su ['ficha de modelo'](https://web.archive.org/web/20250417044145/https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro-preview.pdf) (informe de seguridad) para Gemini 2.5 Pro Preview.
- El informe de pruebas no menciona pruebas externas.

#### 28 de abril de 2025 {#28-april-2025}

- Google [actualiza](https://web.archive.org/web/20250502190015/https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro-preview.pdf) su ficha de modelo para incluir la mención de "probadores externos de terceros", pero no proporciona detalles sobre quiénes son.

#### Abril - junio de 2025 {#april---june-2025}

- [Se han publicado informes técnicos adicionales](https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf). Ninguno de ellos nombra a los probadores externos de terceros ni indica si los gobiernos han participado en las pruebas.

## Conclusión {#conclusion}

- Google ha violado el espíritu del compromiso I al publicar su primer informe de seguridad casi un mes después de la disponibilidad pública y no mencionar pruebas externas en su informe inicial.
- Google ha violado explícitamente el compromiso VIII al no indicar si los gobiernos están involucrados en las pruebas de seguridad, incluso después de que los periodistas les preguntaran directamente.

## Protesta {#protest}

En respuesta, PauseAI realizará nuestra mayor protesta hasta la fecha, con más de 100 asistentes, el lunes 30 de junio.

Registra tu asistencia [aquí](https://pauseai.info/deepmind-protest-2025).
