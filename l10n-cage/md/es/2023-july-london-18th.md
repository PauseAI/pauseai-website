---
title: Protesta de PauseAI en el FCDO, Londres, 18 de julio
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We&#39;re not letting up in London! Today&#39;s protest took place during the first ever UN Security Council meeting on the threat from AI, chaired by UK Foreign Secretary <a href="https://twitter.com/JamesCleverly?ref_src=twsrc%5Etfw">@JamesCleverly</a>. A global pause is the only safe way forward.<br><br>More on UNSC meeting below: <a href="https://t.co/L9hONXogUl">https://t.co/L9hONXogUl</a> <a href="https://t.co/qp4A2fSSvb">pic.twitter.com/qp4A2fSSvb</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1681403296693534725?ref_src=twsrc%5Etfw">July 18, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- Protesta de PauseAI, instando al Consejo de Seguridad de las Naciones Unidas a implementar una pausa global en el desarrollo de sistemas de inteligencia artificial m√°s avanzados.
- D√≥nde: fuera de la Oficina de Relaciones Exteriores, Commonwealth y Desarrollo (FCDO), King Charles Street, Westminster, Londres, SW1A 2AH
- Cu√°ndo: 18 de julio, 4:30 - 5:30 pm
- [Inscr√≠bete](https://docs.google.com/forms/d/e/1FAIpQLSfLoAUfPEhp3bZyUbDnc8HigL_rYC7ykUmmPZvVWas-m2y5bQ/viewform?usp%253Dsf_link)
- [Evento de Facebook](https://fb.me/e/1bawf1ZH1)

## Contacto {#contact}

- Alistair Steward ([twitter](https://twitter.com/alistair___s))

## Comunicado de prensa: PauseAI protesta en la Oficina de Relaciones Exteriores antes de la reuni√≥n del Consejo de Seguridad de la ONU sobre el riesgo de la IA {#press-release-pauseai-protests-foreign-office-ahead-of-un-security-council-meeting-on-ai-risk}

El martes 18 de julio, voluntarios del movimiento PauseAI se reunir√°n en la Oficina de Relaciones Exteriores, Londres, para instar al Consejo de Seguridad de la ONU a implementar una pausa en el desarrollo de sistemas de inteligencia artificial m√°s avanzados. En una [conferencia de prensa](https://youtu.be/USap-tFrTDc?t=3235) la semana pasada, la embajadora del Reino Unido y presidenta del Consejo de Seguridad, Barbara Woodward, declar√≥: "La inteligencia artificial no es en s√≠ misma un actor", demostrando una falta de comprensi√≥n t√©cnica que es com√∫n entre los funcionarios gubernamentales, lo que hace que los riesgos de los sistemas de IA sean subestimados. Muchos expertos en IA creen que la IA superinteligente podr√≠a escapar del control humano, con consecuencias catastr√≥ficas, incluyendo la extinci√≥n humana. El Secretario General de la ONU, Ant√≥nio Guterres, [reconoci√≥ recientemente esta amenaza](https://press.un.org/en/2023/sgsm21832.doc.htm):

> "Las alarmas sobre la √∫ltima forma de inteligencia artificial --- IA generativa --- son ensordecedoras, y son m√°s fuertes por parte de los desarrolladores que la dise√±aron. Estos cient√≠ficos y expertos han llamado al mundo a actuar, declarando que la IA es una amenaza existencial para la humanidad al mismo nivel que el riesgo de la guerra nuclear".

El Consejo de Seguridad de las Naciones Unidas tendr√° una reuni√≥n sin precedentes para discutir estos riesgos de la IA el 18 de julio. Presidida por el Secretario de Relaciones Exteriores del Reino Unido, James Cleverly, la reuni√≥n del Consejo de Seguridad brindar√° la oportunidad de escuchar las opiniones de expertos sobre la IA y comenzar una discusi√≥n entre los 15 miembros del Consejo sobre sus implicaciones. Una [carta abierta](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) (publicada en abril) que pide a las empresas de IA que pausen el desarrollo de sistemas de IA m√°s avanzados ha sido firmada por m√°s de 33.000 personas, incluyendo muchos investigadores de IA y l√≠deres tecnol√≥gicos. Ninguna empresa de IA ha cumplido a√∫n.

> "No podemos esperar que las empresas de IA detengan voluntariamente el desarrollo de sistemas de IA m√°s avanzados - hay demasiada presi√≥n competitiva. Los gobiernos nacionales tienen un problema similar, ya que las naciones tambi√©n compiten. Necesitamos medidas globales. El Consejo de Seguridad de la ONU es uno de los pocos √≥rganos donde se podr√≠a formar un acuerdo internacional para abordar este desaf√≠o. Estamos instando a nuestros l√≠deres a aprovechar esta oportunidad √∫nica para actuar y pausar el desarrollo de sistemas de IA m√°s avanzados". - Miembros de PauseAI

El Reino Unido est√° actualmente liderando a nivel internacional la regulaci√≥n de la seguridad de la IA, ya que el gobierno [anunci√≥ el 7 de junio](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) que organizar√° la primera Cumbre de Seguridad de la IA este oto√±o. Sin embargo, los manifestantes se preocupan de que habr√° demasiada poca acci√≥n, demasiado tarde:

> "Predecir cu√°n r√°pido avanzar√° la IA es incre√≠blemente dif√≠cil. Necesitamos errar en el lado de la precauci√≥n y prepararnos para un escenario en el que obtenemos niveles peligrosos de inteligencia en meses - no a√±os. La reuni√≥n del Consejo de Seguridad de la ONU es el primer momento en que se podr√≠a decidir una pausa global". - Miembros de PauseAI
