---
title: Protesta de PauseAI en Melbourne - 16 de junio
description: Únete a PauseAI en una próxima protesta pacífica en el Melbourne Convention and Exhibition Centre (MCEC), donde Sam Altman dará una charla en Melbourne.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Today we protested in Melbourne, where OpenAI&#39;s Sam Altman was speaking. OpenAI aims to build a superintelligence, which has a serious chance to kill everyone on earth. We&#39;re demanding our governments to step in and <a href="https://twitter.com/hashtag/PauseAI?src=hash&amp;ref_src=twsrc%5Etfw">#PauseAI</a>.<br><br>Press release: <a href="https://t.co/xu7XXTUUyT">https://t.co/xu7XXTUUyT</a> <a href="https://t.co/HtYymXpqjf">https://t.co/HtYymXpqjf</a></p>&mdash; PauseAI (@pause_ai_info) <a href="https://twitter.com/pause_ai_info/status/1669809871867240451?ref_src=twsrc%5Etfw">June 16, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

Únete a #PauseAI en una próxima protesta pacífica en el Melbourne Convention and Exhibition Centre (MCEC), donde Sam Altman dará una charla.

- Fecha y hora: viernes, 16 de junio, 14:00 horas AEST
- Lugar: Entrada principal del MCEC, 1 Convention Centre Place, South Wharf, VIC 3006, Australia
- Horarios de la protesta: 13:30 a 15:00 horas (hora de llegada) y 16:30 horas en adelante (hora de salida)
- Logística: Trae carteles y folletos; no se requiere pago para participar. La entrada de membresía de Startup Victoria es gratuita actualmente.

Únete a nosotros para alzar tu voz por la seguridad de la inteligencia artificial y hacer una diferencia. Por favor, únete al servidor de Discord de #PauseAI, el canal #australia y el Slack de AGI Moratorium, #λ-australia, para más discusiones.

## Comunicado de prensa {#press-release}

El viernes, 16 de junio, voluntarios del movimiento PauseAI se reunirán en el Melbourne Convention and Exhibition Centre para instar al gobierno australiano a tomar la iniciativa en la pausa del desarrollo de sistemas de inteligencia artificial más poderosos y peligrosos.

Un número creciente de expertos en inteligencia artificial firmaron una declaración la semana pasada que afirma:

> "Mitigar el riesgo de extinción por inteligencia artificial debe ser una prioridad global, junto con otros riesgos a escala societal como pandemias y guerra nuclear".

Esto ha sido firmado por prácticamente todos los laboratorios de inteligencia artificial (OpenAI, Google DeepMind, Anthropic) y cientos de científicos de inteligencia artificial, incluyendo a Geoffrey Hinton, considerado el "padre de la inteligencia artificial".

Los investigadores de seguridad de la inteligencia artificial no han llegado a un consenso sobre cuán grande es el riesgo de extinción humana.
Los resultados de la encuesta "Riesgo existencial de la inteligencia artificial" muestran que las estimaciones van desde el 2% hasta el 98%, con un promedio del 30%.

Los manifestantes están instando al gobierno australiano a tomar la iniciativa en la seguridad global de la inteligencia artificial y a pausar el desarrollo de sistemas de inteligencia artificial más peligrosos.
También les están pidiendo que prioricen la pausa en la Cumbre de Seguridad de la Inteligencia Artificial, que está siendo organizada por el Reino Unido y se llevará a cabo a finales de 2023.

Pausar el desarrollo de la inteligencia artificial es un enfoque radicalmente diferente a la seguridad de lo que los directores ejecutivos de los laboratorios de inteligencia artificial como Sam Altman están proponiendo.
OpenAI cree que "sería arriesgado y difícil detener la creación de superinteligencia", por lo que están persiguiendo un mayor desarrollo hacia la superinteligencia.

> "Tenemos una elección: ¿arriesgamos todo para construir una superinteligencia que el público nunca fue consultado, o paramos mientras todavía podemos?" - Manifestantes de PauseAI

> "Las empresas de inteligencia artificial están poniendo todo en riesgo; ya estamos viendo el daño, y empeorará. El desarrollo de la tecnología no es inevitable, y la pausa debe considerarse una opción factible. No podemos ceder el futuro a unos pocos directores ejecutivos que reconocen que están dispuestos a arriesgar la humanidad por sus sueños. Todos merecemos tener voz en nuestro futuro, y una pausa global nos da esa oportunidad".

> "A pesar de reconocer los peligros del desarrollo continuo de la inteligencia artificial, estas empresas simplemente lo están utilizando como excusa para seguir adelante, y parecen negarse a renunciar voluntariamente a este poder peligroso. En tales situaciones, la colaboración global para reinar en este desarrollo peligroso es clave para asegurarnos de que el desarrollo de la tecnología funcione para todos".

> "Es posible que no tengamos el lujo del tiempo. Los desarrollos de la inteligencia artificial están sucediendo a un ritmo frenético, y debemos actuar ahora para prevenir los peores escenarios. La cumbre en otoño podría ser demasiado tarde para prevenir lo peor. Necesitamos que los gobiernos pausen el desarrollo de la inteligencia artificial ahora mismo".

Los manifestantes de PauseAI tienen sugerencias concretas de agenda y propuestas de políticas para la cumbre.

Para más información, por favor visite [PauseAI.info](http://pauseai.info).

## Contacto {#contact}

- Michael Huang ([Twitter](https://twitter.com/michhuan))
