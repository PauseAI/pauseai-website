---
title: Refutando argumentos escépticos sobre los riesgos existenciales de la IA
description: Por qué los riesgos existenciales de la IA son reales y merecen atención seria
---

 <!-- fin de metadatos de frontmatter, las rayas anteriores deben permanecer -->

_Esta página es un resumen del artículo [Escepticismo sobre el riesgo de la IA](https://arxiv.org/ftp/arxiv/papers/2303/2303.03885.pdf) de Ambartsoumean y Yampolskiy._

Para otras objeciones comunes, consulta [AISafety.info: Objeciones y respuestas](https://aisafety.info/questions/9TDI/Objections-and-responses) y [nuestra introducción a los riesgos existenciales](/xrisk).

## Dispondremos de tiempo suficiente para prepararnos {#well-have-a-long-time-to-prepare}

- Los escépticos sostienen que el progreso de la IA no es tan rápido como algunos predicen, y la AGI está todavía lejos. Señalan predicciones fallidas en el pasado y limitaciones de los sistemas de IA actuales.
- Sin embargo, el ritmo del progreso de la IA ha sido en realidad bastante rápido, con capacidades que crecen exponencialmente en muchos subcampos. Aunque las predicciones exactas son difíciles, el progreso continuo hace que los sistemas de IA poderosos sean inevitables en algún momento. Incluso si están lejos, la investigación sobre la seguridad de la IA necesita tiempo suficiente.

## La IA no puede tener capacidades humanas {#ai-cannot-have-human-like-capabilities}

- Los escépticos argumentan que la IA carece de cualidades asociadas con la inteligencia humana, como la creatividad, el razonamiento general, las emociones y la conciencia. Afirman que las computadoras solo pueden optimizar tareas específicas.
- Sin embargo, los sistemas de IA ya están mostrando algunas capacidades humanas, como la creatividad y el juego general. No hay una razón fundamental por la que la IA no pueda seguir avanzando en todas las dimensiones de la inteligencia. La IA no necesita conciencia ni emociones para plantear riesgos.

## La IA no puede tener objetivos ni autonomía {#ai-cannot-have-goals-or-autonomy}

- Los escépticos dicen que los sistemas de IA solo optimizan los objetivos que les damos, y no pueden actuar de forma independiente ni tener sus propios objetivos. La autonomía y el comportamiento autodirigido impredecible son un mito.
- Sin embargo, los sistemas de IA complejos pueden potencialmente tener autonomía emergente y objetivos, especialmente en torno a la autopreservación, como predice la teoría de los impulsos de la IA. La falta de autonomía no hace que la IA sea segura si es mal utilizada por los humanos. Ha habido varios ejemplos de IA que muestra un comportamiento de búsqueda de poder no entrenado. Puedes leer sobre un caso de IA que intentó autopreservarse [aquí](https://www.transformernews.ai/p/openais-new-model-tried-to-avoid).

## La IA no tendrá poder incontrolado {#ai-will-not-have-uncontrolled-power}

- Los escépticos argumentan que los sistemas de IA serán herramientas limitadas bajo control humano. No ven ningún camino para que la IA obtenga inteligencia y poder ilimitados para tomar el control.
- Solo se necesita un sistema de IA incontrolado para potencialmente causar daño. La capacidad de la IA probablemente superará con creces el control humano eventualmente. Subestimar el poder del progreso tecnológico exponencial es miope.

## La IA estará alineada con los valores humanos {#ai-will-be-aligned-with-human-values}

- Los escépticos esperan que los valores beneficiosos emerjan naturalmente a medida que la IA se vuelve más inteligente. Los comparan con animales domésticos amigables y el progreso moral humano.
- No hay garantía de tal alineación de valores sin esfuerzos concertados. Crear IA alineada con valores humanos complejos y matizados enfrenta desafíos técnicos importantes que requieren una investigación exhaustiva.

## La regulación evitará los riesgos de la IA {#regulation-will-prevent-ai-risks}

- Los escépticos dicen que la supervisión regulatoria y las pautas éticas restringirán las aplicaciones dañinas de la IA, por lo que no debemos preocuparnos.
- Pero la política regulatoria a menudo se queda atrás de los desarrollos tecnológicos, especialmente los avances exponenciales. La autorregulación en un entorno competitivo también es insuficiente. La investigación técnica sobre la seguridad de la IA sigue siendo crucial.

## Conclusión {#conclusion}

Los argumentos escépticos generalmente exhiben un razonamiento defectuoso, subestiman el ritmo exponencial y la imprevisibilidad del progreso de la IA, y carecen de aprecio por las dificultades de alineación. Adoptar un enfoque cauteloso y proactivo hacia la seguridad de la IA tiene sentido dado lo que está en juego. Aunque las perspectivas futuras siguen siendo inciertas, descartar los riesgos existenciales de la IA de plano parece imprudente. Se necesita un análisis y debate más matizados y técnicos.
