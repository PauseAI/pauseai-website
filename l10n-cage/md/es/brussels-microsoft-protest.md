---
title: Protesta de PauseAI en Microsoft Bruselas - 23 de mayo de 2023
description: Estamos organizando una protesta en Microsoft para exigir una cumbre que pause el desarrollo de la inteligencia artificial.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- 23 de mayo de 2023, 11:45 - 13:00
- [Centro de Innovación de Microsoft, Rue Montoyer 51, Bruselas, Bélgica](https://goo.gl/maps/bvLbHDt61eSfpZV28?coh=178571&entry=tt)
- [Inscríbete en Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592)

## Únete {#join}

- Únete a nosotros en [Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592) para inscribirte y discutir la protesta.
- Lee el [código de conducta](/protesters-code-of-conduct) de los manifestantes.

## ¿Qué queremos? {#what-do-we-want}

Queremos que nuestros gobiernos (y la UE, en particular) organicen una [cumbre](/summit) sobre los [riesgos](/risks) de la inteligencia artificial.
Queremos que se pause el desarrollo de la inteligencia artificial hasta que estemos suficientemente preparados.

## ¿Por qué en Microsoft? {#why-at-microsoft}

Microsoft invirtió 13.000 millones de dólares en OpenAI, que actualmente está desarrollando los modelos de inteligencia artificial más potentes.
Microsoft está inmersa en una carrera con otras empresas de inteligencia artificial (como Google y Anthropic) para construir los sistemas de inteligencia artificial más potentes lo más rápido posible.
Esta dinámica de mercado es peligrosa porque incentiva a las empresas a centrarse en las capacidades y minimizar los esfuerzos de seguridad.
Esta dinámica plantea [varios riesgos](/risks), incluyendo el [riesgo existencial](/xrisk).

Creemos que Microsoft está en una buena posición para asumir la responsabilidad y apoyar una pausa en los experimentos de inteligencia artificial a gran escala.

## Comunicado de prensa (Nederlands) {#press-release-nederlands}

... (texto en neerlandés, no se traduce)

## Comunicado de prensa {#press-release-english}

El martes 23 de mayo, a las 12:00, tendrá lugar una protesta frente al Centro de Innovación de Microsoft en Bruselas. Voluntarios del nuevo movimiento [PauseAI](http://pauseai.info) se reunirán allí para instar a los gobiernos a discutir los peligros de la inteligencia artificial en una cumbre.

La mitad de los investigadores de inteligencia artificial [creen](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) que existe un 10% o más de probabilidad de que la invención de una inteligencia artificial superhumana signifique el fin de la humanidad. ¿Subirías a un avión si la mitad de los ingenieros aeronáuticos creyeran que hay un 10% de probabilidad de que se estrelle?

Destacados ejemplos de personas que advierten sobre los peligros de la inteligencia artificial incluyen al profesor [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) y al profesor Yoshua Bengio, ambos ganadores del Premio Turing y pioneros de los métodos de inteligencia artificial más exitosos en la actualidad. No solo científicos, sino también líderes de empresas de inteligencia artificial, están preocupados por este peligro:

- Sam Altman (CEO de OpenAI, la empresa detrás de ChatGPT): ["El desarrollo de una inteligencia artificial superhumana es probablemente la mayor amenaza para la existencia continua de la humanidad."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (cofundador de OpenAI): ["La inteligencia artificial tiene el potencial de destruir la civilización."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (cofundador de Microsoft, propietario del 50% de OpenAI): ["La inteligencia artificial podría decidir que los humanos son una amenaza."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (inversor principal de Anthropic, desarrolladores de Claude): ["No he conocido a nadie en laboratorios de inteligencia artificial que diga que el riesgo [de entrenar un modelo de próxima generación] es menor que el 1% de hacer explotar el planeta. Es importante que la gente sepa que se están arriesgando vidas."](https://twitter.com/liron/status/1656929936639430657)

Los avances en el ámbito de la inteligencia artificial han superado las expectativas. En 2020, se estimó que un sistema de inteligencia artificial superaría los exámenes de ingreso a la universidad en 2050. Este objetivo se logró en marzo de 2023 con el sistema GPT-4 de OpenAI. Esta inteligencia artificial tiene un [coeficiente intelectual verbal de 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), habla 23 idiomas, puede programar y [puede engañar a las personas](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Afortunadamente, GPT-4 todavía tiene limitaciones. Por ejemplo, no puede [hackear o escribir virus informáticos](https://pauseai.info/cybersecurity-risks) de manera efectiva, pero es posible que estas habilidades estén a solo unas pocas innovaciones de distancia. Dado el ritmo actual de inversión en inteligencia artificial, este punto se está acercando [rápidamente](https://pauseai.info/urgency).

Estos enormes e inesperados saltos en las capacidades han llevado a muchos expertos a solicitar una pausa en el desarrollo de la inteligencia artificial a través de una [carta abierta](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) dirigida a las principales empresas de inteligencia artificial. La carta ha sido firmada más de 27.000 veces, en su mayoría por investigadores de inteligencia artificial y destacados expertos en tecnología. Se necesita una pausa para trabajar en la legislación de la inteligencia artificial, abordar el problema de la alineación de la inteligencia artificial y adaptarnos como sociedad a esta nueva tecnología. Una [encuesta reciente](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) en los Estados Unidos muestra un apoyo significativo a una pausa, con más del 60% del público a favor. Desafortunadamente, parece que las empresas no están dispuestas a poner en riesgo sus posiciones competitivas deteniéndose voluntariamente. Estas empresas de inteligencia artificial están atrapadas en una carrera hacia el abismo, donde la seguridad cada vez se vuelve más secundaria para mejorar las capacidades. Por lo tanto, la pausa debe ser impuesta por los gobiernos. Implementar una pausa nacional también es un desafío, ya que los países tienen razones para no ser los primeros en pausar. Por lo tanto, se necesita una solución internacional: una cumbre. PauseAI hace un llamado a nuestros gobiernos para que organicen esa cumbre.

Para obtener más información, visite [PauseAI.info](http://pauseai.info).

## Medios {#media}

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hoy nos reunimos en Bruselas. Pedimos a nuestros gobiernos que organicen una cumbre para discutir los riesgos de la inteligencia artificial y prevenir el desarrollo de una inteligencia artificial superinteligente. <a href="https://twitter.com/hashtag/pauseai?src=hash&amp;ref_src=twsrc%5Etfw">#pauseai</a> (1/5) <a href="https://t.co/tXdeftTNAp">pic.twitter.com/tXdeftTNAp</a></p>&mdash; Joep Meindertsma (@joepmeindertsma) <a href="https://twitter.com/joepmeindertsma/status/1661047436905725953?ref_src=twsrc%5Etfw">23 de mayo de 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>
