---
title: Por qué necesitamos cumbres de seguridad de IA
description: Por qué es necesario que se lleve a cabo la cumbre de seguridad de IA y qué se debe lograr.
---

 <!-- final de los metadatos de Frontmatter, las líneas de guiones arriba deben permanecer -->

La inteligencia artificial (IA) plantea numerosos [riesgos](/risks) para la humanidad, incluyendo el [riesgo de extinción](/xrisk).
El avance en las capacidades de la IA se está acelerando a un [ritmo vertiginoso](/urgency), y no estamos preparados para las consecuencias.
Las empresas de IA están inmersas en una carrera hacia el abismo, donde la seguridad no es la principal prioridad.
Necesitamos que los gobiernos intervengan y eviten que la IA alcance niveles superhumanos antes de que sepamos cómo hacerlo de manera segura.
Esta [pausa](/proposal) debe producirse a nivel internacional porque los países están inmersos en una carrera similar a la de las empresas.
Los acuerdos internacionales significan _tratados_, y eso requiere que los países se reúnan en persona y negocien.
**La única manera de lograr una pausa real es a través de una cumbre.**

Ha habido algunos ejemplos de cumbres internacionales y tratados resultantes que han tenido éxito en la reducción de riesgos:

- **Protocolo de Montreal** (1987): El Protocolo de Montreal es un tratado ambiental internacional diseñado para proteger la capa de ozono mediante la eliminación gradual de la producción y consumo de sustancias que agotan el ozono. Ha tenido un gran éxito en reducir el uso de sustancias como los clorofluorocarbonos (CFC) y ha contribuido a la recuperación gradual de la capa de ozono.
- **Convenio de Estocolmo sobre Contaminantes Orgánicos Persistentes** (2001): El Convenio de Estocolmo es un tratado internacional destinado a proteger la salud humana y el medio ambiente de los contaminantes orgánicos persistentes (COP). Estos son productos químicos tóxicos que persisten en el medio ambiente, se bioacumulan en los seres vivos y pueden tener graves efectos adversos en la salud humana y los ecosistemas. Los científicos expresaron su preocupación por los efectos nocivos de los COP, incluida su capacidad para viajar largas distancias a través de corrientes de aire y agua. El convenio condujo a la prohibición o restricciones severas en la producción y uso de varios COP, incluyendo los bifenilos policlorados (PCB), el diclorodifeniltricloroetano (DDT) y las dioxinas.

## Cumbres Pasadas {#past-summits}

### Cumbre de Seguridad de IA del Reino Unido 2023 {#2023-uk-ai-safety-summit}

El objetivo principal de PauseAI era convencer a un gobierno de organizar dicha cumbre.
Solo 5 semanas después de la primera protesta de PauseAI, el gobierno del Reino Unido [anunció](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) que sería el anfitrión de una cumbre de seguridad de IA, que se llevó a cabo el 1 y 2 de noviembre de 2023.
La cumbre fue relativamente pequeña (solo se invitó a 100 personas) y se llevó a cabo en Bletchley Park.
Aunque no condujo a un tratado vinculante, sí llevó a la "Declaración de Bletchley", que fue firmada por los 28 países asistentes.
En esta declaración, los países reconocieron los riesgos de la IA (incluidos "problemas de control relacionados con la alineación con la intención humana").
Esta cumbre también condujo al anuncio de dos cumbres de seguimiento para 2024, en Seúl y París.

### Cumbre de Seguridad de IA de Corea del Sur 2024 (21 y 22 de mayo) {#2024-south-korea-ai-safety-summit-may-21st-22nd}

Durante meses, no estuvo claro cuál sería el alcance de esta cumbre de Seúl.
Todo lo que sabíamos era que iba a ser un ["mini cumbre virtual"](https://www.bracknellnews.co.uk/news/national/23898764.ai-safety-institute-will-make-uk-global-hub-rishi-sunak-says/).
Una forma bastante poco ambiciosa de abordar los llamados sumamente alarmantes para la regulación.
En abril de 2024, el gobierno del Reino Unido [anunció oficialmente](https://www.gov.uk/government/news/uk-and-republic-of-korea-to-build-on-legacy-of-bletchley-park) la segunda cumbre de seguridad de IA.
Organizamos [una protesta el 13 de mayo](/2024-may) para convencer a nuestros ministros de asistir a la cumbre (algunos [no planeaban asistir](https://www.reuters.com/technology/second-global-ai-safety-summit-faces-tough-questions-lower-turnout-2024-04-29/)) e iniciar las negociaciones de un tratado hacia una pausa.

La Cumbre condujo a lo siguiente:

1. 16 empresas (las empresas de IA más prominentes) firmaron los ["Compromisos de Seguridad de IA de Frontera"](https://www.gov.uk/government/news/historic-first-as-companies-spanning-north-america-asia-europe-and-middle-east-agree-safety-commitments-on-development-of-ai?utm_source=substack&utm_medium=email), lo que significa que estas empresas publicarán RSP. Los compromisos voluntarios anteriores [fueron ignorados](https://www.politico.eu/article/rishi-sunak-ai-testing-tech-ai-safety-institute/).
2. Se firmó [una nueva declaración](https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024) por 27 países.

### Conferencia de Seguridad de IA de San Francisco, noviembre 2024 {#november-2024-san-francisco-ai-safety-conference}

En septiembre, el AISI y el gobierno de EE. UU. nos sorprendieron con el anuncio de una nueva cumbre.
O, más precisamente, dos nuevas reuniones en San Francisco.

El **20 y 21 de noviembre**, la primera reunión internacional de [institutos de seguridad de IA](https://www.commerce.gov/news/press-releases/2024/09/us-secretary-commerce-raimondo-and-us-secretary-state-blinken-announce), organizada por el gobierno de EE. UU., tuvo como objetivo "comenzar a promover la colaboración global y el intercambio de conocimientos sobre la seguridad de la IA".
Los miembros iniciales de la Red Internacional de Institutos de Seguridad de IA son Australia, Canadá, la Unión Europea, Francia, Japón, Kenia, la República de Corea, Singapur, el Reino Unido y los Estados Unidos.
China está notablemente ausente de esta lista, a pesar de que se [anunció el nuevo Instituto de Seguridad de IA de China](https://x.com/yi_zeng/status/1831133250946838740).

El **21 y 22 de noviembre**, el AISI británico [organizó una conferencia en San Francisco](https://www.aisi.gov.uk/work/conference-on-frontier-ai-safety-frameworks).
El objetivo principal aquí fue "convocar a expertos de empresas signatarias y de organizaciones de investigación para discutir los desafíos más apremiantes en el diseño e implementación de marcos de seguridad de IA de frontera".

### Cumbre de Acción de IA de Francia 2025 {#2024-2025-france-ai-safety-action-summit}

Durante la cumbre de Bletchley de 2023, Francia optó por organizar la siguiente gran cumbre en noviembre de 2024.
Francia la pospuso hasta febrero de 2025.
También se cambió el nombre a "Cumbre de Acción de IA", eliminando el importante enfoque de "Seguridad".
Estuvo liderada por Anne Bouverot, escéptica de la IA, quien [resta importancia](https://legrandcontinent-eu.translate.goog/es/2023/12/08/la-ia-no-nos-sustituira-una-conversacion-con-anne-bouverot-yann-le-cun-y-alexandre-viros/?_x_tr_sl=es&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc) al "discurso alarmista", comparando la IA con calculadoras y comparando las preocupaciones sobre la seguridad de la IA con las preocupaciones sobre el Y2K, asegurando que "la IA no nos va a reemplazar, sino que nos ayudará".
[Protestamos](/2025-february) por la falta de enfoque en la seguridad de la cumbre.

La cumbre ha sido ampliamente criticada por la comunidad de seguridad de IA.
Recomendamos leer [el artículo de Zvi](https://thezvi.substack.com/p/the-paris-ai-anti-safety-summit) sobre la ["Cumbre Contra la Seguridad de la IA"](https://thezvi.substack.com/p/the-paris-ai-anti-safety-summit).

## Próximas Cumbres {#coming-summits}

- India fue coanfitriona de la cumbre de París y será la anfitriona de la siguiente. Lamentablemente, esperamos que carezca de discusiones significativas sobre seguridad/regulación.
- La ONU organiza la [cumbre AI For Good](https://aiforgood.itu.int/) en Suiza, en julio de 2025.

## Lo que nos falta {#what-were-missing}

Ninguna de las cumbres planificadas se centra en la seguridad o la regulación internacional.
Necesitamos que un país dé un paso al frente y organice una cumbre centrada en la seguridad y la regulación internacional.
Nuestro trabajo es encontrar a un político que haga esto.
