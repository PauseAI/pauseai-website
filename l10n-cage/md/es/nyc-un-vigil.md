---
title: Vigilia con velas de PauseAI en la sede de la ONU en Nueva York, 3 de junio
---

 <!-- fin de metadatos de frontmatter, las líneas de arriba deben permanecer -->

- Vigilia con velas para concienciar sobre el riesgo existencial de la inteligencia artificial.
- 3 de junio, 7:30PM a 9PM. El sol se pone a las 8:15 aquí.
- Sede de las Naciones Unidas en la ciudad de Nueva York.
- [Inscríbete](https://forms.gle/hsVetUDx3R1w6yj59)

## Comunicado de prensa {#press-release}

El sábado 3 de junio, al atardecer, se llevará a cabo una vigilia con velas frente a la sede de las Naciones Unidas.
La vigilia es un llamado a la acción y a la esperanza, para que los seres humanos puedan unirse y hacer frente a la creciente amenaza existencial que plantea la inteligencia artificial.
Voluntarios del movimiento [PauseAI](http://pauseai.info) se reunirán allí para instar a los gobiernos a organizar una cumbre que detenga el desarrollo de esta tecnología peligrosa.

La mitad de los investigadores en inteligencia artificial [creen](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) que hay un 10% o más de probabilidad de que la invención de una inteligencia artificial superhumana signifique el fin de la humanidad. ¿Subirías a un avión si la mitad de los ingenieros aeronáuticos pensaran que hay un 10% de probabilidad de que se estrelle?

Destacados expertos en inteligencia artificial, como el profesor [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) y el profesor [Yoshua Bengio](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/), ambos ganadores del Premio Turing y pioneros de los métodos de inteligencia artificial más exitosos de hoy en día, han advertido sobre los peligros de la inteligencia artificial. No solo científicos, sino también líderes de empresas de inteligencia artificial, están preocupados por este peligro:

- Sam Altman (CEO de OpenAI, la empresa detrás de ChatGPT): ["El desarrollo de una inteligencia artificial superhumana es probablemente la mayor amenaza para la existencia continua de la humanidad."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (cofundador de OpenAI): ["La inteligencia artificial tiene el potencial de destrucción civilizatoria."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (cofundador de Microsoft, propietario del 50% de OpenAI): ["La inteligencia artificial podría decidir que los humanos son una amenaza."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (inversionista principal en Anthropic, constructores de Claude): ["No he conocido a nadie en laboratorios de inteligencia artificial que diga que el riesgo [de entrenar un modelo de próxima generación] es menor que el 1% de hacer explotar el planeta. Es importante que la gente sepa que se están arriesgando vidas."](https://twitter.com/liron/status/1656929936639430657)

Los avances en el campo de la inteligencia artificial han superado las expectativas. En 2020, se estimó que un sistema de inteligencia artificial superaría los exámenes de ingreso a la universidad para 2050. Este objetivo se logró en marzo de 2023 con el GPT-4 de OpenAI. Esta inteligencia artificial tiene un [coeficiente intelectual verbal de 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), habla 23 idiomas, puede programar y [puede engañar a las personas](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Afortunadamente, el GPT-4 todavía tiene limitaciones. Por ejemplo, no puede [hackear o escribir virus informáticos](https://pauseai.info/cybersecurity-risks) de manera efectiva, pero es posible que estas habilidades estén solo a unas pocas innovaciones de distancia. Dado el ritmo actual de inversión en inteligencia artificial, este punto se está [acercando rápidamente](https://pauseai.info/urgency).

Estos saltos masivos y repentinos en capacidades han llevado a muchos expertos a solicitar una pausa en el desarrollo de la inteligencia artificial a través de una [carta abierta](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) dirigida a las principales empresas de inteligencia artificial. La carta ha sido firmada más de 27.000 veces, principalmente por investigadores en inteligencia artificial y luminarias tecnológicas. Se necesita una pausa para trabajar en la legislación de la inteligencia artificial, trabajar en el problema de la alineación de la inteligencia artificial y ajustarse como sociedad a esta nueva tecnología. Una [encuesta reciente](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) en los Estados Unidos muestra un apoyo significativo a una pausa, con más del 60% del público a favor. Desafortunadamente, parece que las empresas no están dispuestas a arriesgar voluntariamente sus posiciones competitivas deteniéndose. Estas empresas de inteligencia artificial están atrapadas en una carrera hacia el fondo, donde la seguridad cada vez tiene menos prioridad en comparación con mejorar las capacidades. Por lo tanto, la pausa debe ser impuesta por los gobiernos. Implementar una pausa nacional también es un desafío, ya que los países tienen razones para no ser los primeros en pausar. Por lo tanto, se necesita una solución internacional: una cumbre. PauseAI está llamando a nuestros gobiernos a organizar esa cumbre.

Para obtener más información, por favor visite [PauseAI.info](http://pauseai.info).
