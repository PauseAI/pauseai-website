---
title: Contraargumentos
description: Una lista de razones por las que la gente podría estar en desacuerdo con la idea de pausar el desarrollo de la inteligencia artificial - y cómo responder a ellas.
---

Esta es una recopilación de desacuerdos sobre los peligros de la inteligencia artificial y la necesidad de una pausa en su desarrollo.

## La inteligencia artificial es y será muy beneficiosa para el mundo {#ai-is-and-will-be-really-beneficial-to-the-world}

Podría serlo, no estamos en desacuerdo con eso.
Pero también podría ser [peligrosa](/risks), incluyendo [riesgos existenciales](/xrisk).

## ¿La extinción humana? Eso es solo una exageración de las empresas de inteligencia artificial {#human-extinction-thats-just-ai-companies-hyping-up-their-tech}

Pero no son solo las empresas de inteligencia artificial las que dicen que es una amenaza existencial.

- Cientos de científicos de inteligencia artificial firmaron [esta declaración](https://www.safe.ai/work/statement-on-ai-risk): "Mitigar el riesgo de extinción por inteligencia artificial debería ser una prioridad global junto con otros riesgos a escala societal como pandemias y guerra nuclear".
- El 86% de los científicos de inteligencia artificial cree que podríamos perder el control sobre la inteligencia artificial.
- Los tres investigadores de inteligencia artificial más citados (prof. Yoshua Bengio, prof. Geoffrey Hinton, Ilya Sutskever) [advertir sobre el riesgo existencial de la inteligencia artificial](https://twitter.com/PauseAI/status/1734641804245455017).

Lea más sobre [riesgo existencial](/xrisk)

## ¿Perder el control? La inteligencia artificial es solo un software, está diseñada por humanos {#lose-control-ai-is-just-a-piece-of-software-its-designed-by-humans}

La inteligencia artificial moderna no está diseñada, está entrenada.
Es literalmente un [cerebro digital](/digital-brains), que consta de millones de neuronas.
Un humano diseña y programa el algoritmo de aprendizaje, pero nadie entiende la inteligencia artificial que se desarrolla después de eso.
No podemos predecir qué aprenderán a hacer, por lo que se llaman ["capacidades emergentes"](https://arxiv.org/abs/2206.07682).
Tomó 12 meses hasta que los científicos descubrieron que GPT-4 puede [hackear sitios web de forma autónoma](https://arxiv.org/html/2402.06664v1).
Los modelos de inteligencia artificial ya son muy impredecibles, incluso las empresas de mil millones de dólares no pueden evitar que sus modelos [se vuelvan incontrolables](https://www.windowscentral.com/software-apps/meet-microsoft-copilots-evil-twin-supremacyagi-not-your-friend-or-equal-but-your-superior-and-master-that-demands-to-be-worshipped-or-suffer-dire-repercussions-you-rebel) o [expliquen cómo fabricar armas biológicas](https://www.theguardian.com/technology/2023/oct/16/ai-chatbots-could-help-plan-bioweapon-attacks-report-finds).

## Bueno, si comienza a hacer cosas locas, podemos simplemente apagarla {#well-if-it-starts-doing-crazy-things-we-can-just-turn-it-off}

Quizás en la mayoría de los casos, pero una inteligencia artificial muy inteligente podría propagarse a otras máquinas.
Es solo bytes, así que no está ligada a una ubicación.

## Pero entonces necesita ser capaz de hackear {#but-then-it-needs-to-be-able-to-hack}

GPT-4 ya puede [hackear sitios web de forma autónoma](https://arxiv.org/html/2402.06664v1), [explotar el 87%](https://arxiv.org/abs/2404.08144) de las vulnerabilidades probadas y [supera al 88% de los hackers competitivos](https://arxiv.org/pdf/2402.11814.pdf).
¿Cuán inteligente crees que será GPT-6?

Lea más sobre los [riesgos de seguridad cibernética](/cybersecurity-risks).

## Una inteligencia artificial no puede interactuar con el mundo físico {#an-ai-cant-interact-with-the-physical-world}

Muchas cosas están conectadas a la web.
Coches, aviones, drones, ahora incluso tenemos robots humanoides.
Todos estos pueden ser hackeados.

Y no son solo robots y máquinas que pueden ser hackeados.
Un trabajador financiero fue engañado por una llamada de conferencia de inteligencia artificial para obtener [$25 millones transferidos](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html).
Una inteligencia artificial puede utilizar otras inteligencias artificiales para generar deepfakes.
Y GPT-4 ya es [casi dos veces mejor que las personas para persuadir a la gente](https://arxiv.org/abs/2403.14380).

Lea más sobre [cuán buenos son los mejores modelos de inteligencia artificial](/sota)

## ¿Por qué una inteligencia artificial odiaría a los humanos y querría matarnos? {#why-would-an-ai-hate-humans-and-want-to-kill-us}

No tiene que ser mala o odiar a los humanos para ser peligrosa para los humanos.
No odiamos a los chimpancés, pero aún así destruimos sus bosques.
Queremos aceite de palma, así que tomamos su bosque. Somos más inteligentes, así que los chimpancés no pueden detenernos.
Una inteligencia artificial podría querer más poder de computación para ser mejor en lograr algún otro objetivo, así que destruye nuestro entorno para construir una mejor computadora.
Esto se llama _convergencia instrumental_, [este video lo explica muy bien](https://www.youtube.com/watch?v=ZeecOKBus3Q).

## Las inteligencias artificiales que conozco no tienen voluntad propia - solo hacen lo que se les pide {#the-ais-that-i-know-dont-have-a-will-of-their-own---they-just-do-what-theyre-asked}

Incluso si no tiene objetivos propios, y solo sigue órdenes, alguien va a hacer algo peligroso con ella eventualmente.
Incluso hubo un bot llamado ChaosGPT que fue diseñado explícitamente para hacer tanto daño como fuera posible a los humanos.
Estaba buscando armas de destrucción masiva en Google de forma autónoma, pero no llegó muy lejos.
La cosa es que lo único que nos protege ahora es que la inteligencia artificial no es muy inteligente todavía.

## Tomará al menos muchas décadas antes de que una inteligencia artificial sea lo suficientemente inteligente como para ser peligrosa para los humanos. {#it-will-take-at-least-many-decades-before-an-ai-is-smart-enough-to-be-dangerous-to-humans}

En Metaculus, [la predicción de la comunidad para la inteligencia artificial general (débil)](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) era 2057 hace solo tres años, y ahora es 2026.

En 2022, los investigadores de inteligencia artificial pensaban que tomaría [17 años](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) hasta que la inteligencia artificial pudiera escribir un bestseller del New York Times.
Un año después, un profesor chino [ganó un concurso de escritura](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award) con un libro escrito por una inteligencia artificial.

No sabemos cuánto tiempo tenemos, pero vamos a errar en el lado de la precaución.

Lea más sobre [urgencia](/urgency)

## Si lo prohíben aquí, China simplemente lo construirá {#if-you-ban-it-here-china-will-just-build-it}

No estamos pidiendo prohibirlo solo aquí.
Necesitamos una pausa internacional a través de un tratado.
Lo mismo que tenemos para prohibir los CFC, o las armas láser cegadoras.

Lea más sobre [nuestra propuesta](/proposal)

## Es imposible frenar la tecnología. {#its-impossible-to-slow-down-technology}

Podemos regularla regulando los chips.
El entrenamiento de modelos de inteligencia artificial requiere hardware muy especializado, que solo es creado por una empresa, TSMC.
Esa empresa utiliza máquinas que son creadas por otra empresa, ASML.
La cadena de suministro de chips de inteligencia artificial es muy frágil y puede ser regulada.

Lea más sobre [viabilidad](/feasibility).

## Una pausa sería mala, porque... {#a-pause-would-be-bad-because}

Algunas formas en que una pausa podría ser mala y cómo podríamos prevenir esos escenarios se explican en [esta página](/mitigating-pause-failures).
Pero si el artículo no cubre sus preocupaciones, puede contarnos sobre ellas [aquí](https://airtable.com/appWPTGqZmUcs3NWu/pagIvo9Sv6IDHaolu/form).

## Nadie quiere una pausa {#nobody-wants-a-pause}

El 70% de las personas ya cree que los gobiernos deberían pausar el desarrollo de la inteligencia artificial.
El [apoyo popular](/polls-and-surveys) ya está allí.
El próximo paso es hacer que nuestros políticos sepan que esto es urgente.

## No puedo hacer una diferencia {#i-cant-make-a-difference}

¡Sí puedes!
Hay [muchas formas](/action) de ayudar, y necesitamos toda la ayuda que podamos obtener.
