---
title: Protesta de PauseAI en la Oficina de IA - 29 de junio
---

 <!-- fin de metadatos de frontmatter, las rayas anteriores deben permanecer -->

- Protesta de PauseAI, instando a Rishi Sunak a implementar una pausa en el desarrollo de IA.
- Dónde: Oficina de IA, Departamento de Ciencia, Innovación y Tecnología, 100 Parliament Street, Westminster, Londres, SW1A 2BQ
- Cuándo: 29 de junio, 16:00 - 18:00
- [Regístrate aquí](https://forms.gle/t1FvzqaEBmZuBuXS7)

## Comunicado de prensa {#press-release}

El jueves 29 de junio, voluntarios del movimiento [PauseAI](http://pauseai.info) se reunirán en la Oficina de IA, Plaza del Parlamento, Londres, para instar al gobierno del Reino Unido a tomar la iniciativa en la pausa del desarrollo de sistemas de IA más poderosos y peligrosos.

Un gran número de expertos en IA [firmaron una declaración](https://www.safe.ai/statement-on-ai-risk) a principios de este mes que afirma:

> "Mitigar el riesgo de extinción por IA debe ser una prioridad global, al igual que otros riesgos a escala societal, como pandemias y guerras nucleares".

Esta declaración ha sido firmada por prácticamente todos los laboratorios de IA (OpenAI, Google DeepMind, Anthropic) y cientos de científicos de IA, incluyendo a Geoffrey Hinton, considerado el "Padre de la IA".

Los investigadores de seguridad de IA no han llegado a un consenso sobre la magnitud del riesgo de extinción humana.
Los resultados de la ["Encuesta sobre riesgo existencial de IA"](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results) muestran que las estimaciones varían desde el 2% hasta el 98%, con un promedio del 30%.

El Reino Unido está tomando actualmente la iniciativa internacional en regulaciones de seguridad de IA, ya que el gobierno [anunció el 7 de junio](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) que organizará la primera Cumbre de Seguridad de IA este otoño.

La semana pasada, Rishi Sunak presentó la Fuerza de Tarea de Seguridad de IA, con Ian Hogarth como su director.
Esta fuerza de tarea cuenta con una financiación inicial de £100 millones del gobierno.

Sin embargo, [Sunak tuiteó](https://twitter.com/RishiSunak/status/1670355987457294337) que el objetivo de la Fuerza de Tarea de Seguridad de IA es también "Acelerar drásticamente la capacidad de IA del Reino Unido".
Esto contrasta con lo que el recién nombrado director de la Fuerza de Tarea de Seguridad de IA, Ian Hogarth, escribió en mayo, en su artículo en el Financial Times "Debemos frenar la carrera hacia una IA similar a Dios".

Los manifestantes están instando a Rishi Sunak a tomar la iniciativa en la seguridad de IA global y a pausar el desarrollo de sistemas de IA más peligrosos en el Reino Unido.

> "Acelerar ahora es una estrategia peligrosa, y el mensaje equivocado para las naciones en la cumbre de seguridad de IA. Rishi Sunak debería liderar con el ejemplo y implementar la Pausa" - Manifestantes de PauseAI

> "El Reino Unido está organizando una cumbre de seguridad de IA a finales de este año, pero puede ser demasiado tarde. Necesitamos frenar ahora mismo" - Manifestantes de PauseAI

> "El Reino Unido está en una posición ideal para desarrollar los requisitos de seguridad concretos que sentarían un precedente para la cumbre de seguridad de IA más adelante este año. No hay otro país que tenga esta concentración de expertos en seguridad de IA" - Manifestantes de PauseAI

> "Implementar una pausa nacional en el desarrollo de IA sería un paso audaz, pero nos daría el tiempo que necesitamos para hacerlo bien, y sentaría un precedente para que otros países sigan. Esto es esencial para que la cumbre de seguridad de IA sea un éxito" - Manifestantes de PauseAI

> "Las empresas de IA están poniendo todo en riesgo; ya estamos viendo el daño, y empeorará mucho más. El desarrollo de la tecnología no es inevitable, y la pausa debería considerarse una opción factible. No podemos ceder el futuro a unos pocos directivos que reconocen que están dispuestos a arriesgar la humanidad por sus sueños. Todos merecemos tener voz en nuestro futuro, y una pausa global nos da esa oportunidad. Sin embargo, esa pausa global se vuelve mucho más probable si implementamos una pausa nacional primero" - Manifestantes de PauseAI

> "Puede que no tengamos el lujo del tiempo. Los desarrollos de IA están sucediendo a un ritmo frenético, y necesitamos actuar ahora para prevenir los escenarios más graves. La cumbre de otoño podría ser incluso demasiado tarde para prevenir lo peor. Instamos a Rishi Sunak a detener los desarrollos de IA antes de la cumbre. Incluso si solo el Reino Unido y EE. UU. acuerdan pausar hasta la cumbre, habremos dado un gran paso hacia la prevención de los escenarios más graves" - Manifestantes de PauseAI

Los manifestantes de PauseAI tienen [sugerencias concretas de agenda](/summit) y [propuestas de políticas](/proposal) para la cumbre.

Para más información, por favor visite [PauseAI.info](http://pauseai.info).
