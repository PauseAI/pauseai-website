---
title: Protesta de PauseAI en el FCDO, Londres, 13 de julio
description: Protesta de PauseAI, instando al Consejo de Seguridad de las Naciones Unidas a implementar una pausa global en las ejecuciones de entrenamiento de IA más grandes.
---

- Protesta de PauseAI, instando al Consejo de Seguridad de las Naciones Unidas a implementar una pausa global en las ejecuciones de entrenamiento de IA más grandes.
- Lugar: fuera de la Oficina de Relaciones Exteriores, Commonwealth y Desarrollo (FCDO), King Charles Street, Westminster, Londres, SW1A 2AH
- Fecha y hora: 13 de julio, 16:30 - 17:30
- [Inscríbete](https://docs.google.com/forms/d/e/1FAIpQLSfW_E_Q92EEdv6AwHdsEbyR66tOUByo-wFrc3SU4zIL6HTjxw/viewform?usp%253Dsf_link)

## Contacto {#contact}

- Alistair Steward ([twitter](https://twitter.com/alistair___s))

## Comunicado de prensa: PauseAI protesta en la Oficina de Relaciones Exteriores antes de la reunión del Consejo de Seguridad de la ONU sobre el riesgo de la IA {#press-release-pauseai-protests-foreign-office-ahead-of-un-security-council-meeting-on-ai-risk}

El jueves 13 de julio, voluntarios del movimiento PauseAI se reunirán en la Oficina de Relaciones Exteriores, Londres, para instar al Consejo de Seguridad de la ONU a implementar una pausa en las ejecuciones de entrenamiento de los sistemas de IA más poderosos. En una [conferencia de prensa](https://youtu.be/USap-tFrTDc?t=3235) celebrada la semana pasada, la embajadora del Reino Unido y presidenta del Consejo de Seguridad, Barbara Woodward, declaró: "La inteligencia artificial no es un actor en sí misma", lo que demuestra una falta de comprensión técnica que es común entre los funcionarios gubernamentales y que lleva a subestimar gravemente los riesgos de los futuros sistemas de IA. Muchos expertos en IA creen que la IA superhumana podría escapar del control humano, con consecuencias catastróficas, incluyendo la extinción humana. El Secretario General de la ONU, António Guterres, [reconoció recientemente esta amenaza](https://press.un.org/en/2023/sgsm21832.doc.htm):

> "Las alarmas sobre la última forma de inteligencia artificial --- la IA generativa --- son ensordecedoras, y son más fuertes entre los desarrolladores que la diseñaron. Estos científicos y expertos han llamado a la acción al mundo, declarando que la IA es una amenaza existencial para la humanidad al mismo nivel que el riesgo de la guerra nuclear".

El Consejo de Seguridad de la ONU celebrará una reunión sin precedentes para discutir estos riesgos de la IA el 18 de julio. Presidida por el Secretario de Relaciones Exteriores del Reino Unido, James Cleverly, la reunión del Consejo de Seguridad brindará la oportunidad de escuchar las opiniones de expertos sobre la IA y comenzar una discusión entre los 15 miembros del Consejo sobre sus implicaciones. Una [carta abierta](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) (publicada en abril) que pide a las empresas de IA que pausen sus ejecuciones de entrenamiento ha sido firmada por más de 33.000 personas, incluyendo a muchos investigadores de IA y líderes tecnológicos. Ninguna empresa de IA ha cumplido aún.

> "No podemos esperar que las empresas de IA detengan voluntariamente el entrenamiento de nuevos modelos de IA - la presión competitiva es demasiado fuerte. Los gobiernos nacionales enfrentan un problema similar, ya que las naciones también compiten. Necesitamos medidas globales. El Consejo de Seguridad de la ONU es uno de los pocos órganos donde se podría formar un tratado internacional de este tipo. Estamos instando a nuestros líderes a aprovechar esta oportunidad única para actuar y pausar las ejecuciones de entrenamiento de IA". - Miembros de PauseAI

El Reino Unido está liderando actualmente la regulación de la seguridad de la IA a nivel internacional, ya que el gobierno [anunció el 7 de junio](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) que organizará la primera Cumbre de Seguridad de la IA este otoño. Sin embargo, los manifestantes se preocupan de que habrá demasiada poca acción, demasiado tarde:

> "Predecir cuán rápido avanzará la IA es extremadamente difícil. Debemos errar en el lado de la precaución y prepararnos para un escenario en el que obtenemos niveles peligrosos de inteligencia en meses - no años. La reunión del Consejo de Seguridad de la ONU es el primer momento en que se podría decidir una pausa global". - Miembros de PauseAI
