---
title: Actúa
description: Formas de ayudar a reducir el riesgo de la IA.
---

La IA no será más segura a menos que actuemos de manera decisiva para impulsar la seguridad.
Elige una actividad a continuación según tus intereses o habilidades.

## Para todos {#for-everyone}

### Exige acción gubernamental {#demand-government-action}

- **Escribe a tus representantes**: Hemos descubierto que los correos electrónicos son sorprendentemente efectivos y requieren relativamente poco esfuerzo. Si no te sientes seguro sobre qué escribir, [comienza con nuestro constructor de correos electrónicos](/email-builder). Cuando obtengas una reunión, debes consultar nuestros [consejos para reuniones con representantes](/lobby-tips).
- **Llama a tus representantes**: Intenta llamar a las oficinas de los legisladores mientras tienes un conjunto de puntos de discusión a la vista para que te mantengas en tema.
- **Participa en protestas**: Únete a [una de las protestas](https://pauseai.info/protests) o [organiza una tú mismo](https://pauseai.info/organizing-a-protest).
- **Firma peticiones**: [**La nuestra**](/statement), [Tratado Internacional de IA](https://aitreaty.org), [Prohibir la superinteligencia](https://chng.it/Djjfj2Gmpk), [Exige IA responsable](https://www.change.org/p/artificial-intelligence-time-is-running-out-for-responsible-ai-development-91f0a02c-130a-46e1-9e55-70d6b274f4df).

### Informa a las personas que te rodean {#inform-people-around-you}

- **Comparte información sobre el riesgo de la IA** en tus redes sociales. Uno de [estos videos](https://www.youtube.com/watch?v=xBqU1QxCao8&list=PLI46NoubGtIJa0JVCBR-9CayxCOmU0EJt) o este sitio web pueden ser un buen comienzo. Y no olvides etiquetarnos en tus publicaciones.
- **Habla con las personas en tu vida** sobre la seguridad de la IA. Responde a sus preguntas y anímalos a actuar también. Utiliza nuestros [contraargumentos](/counterarguments) para ayudarte a ser más persuasivo.
- **Distribuye información**: [Distribuir folletos](/tabling) y [repartir volantes](/flyering) son excelentes formas de llegar a muchas personas en un corto período de tiempo.
- **Asiste a eventos locales**: Muchas ciudades tienen eventos (gratuitos o de bajo costo) sobre política de IA y tecnología. Asistir a estos eventos es una excelente forma de establecer contactos y compartir tus inquietudes.

### Apoya a PauseAI {#support-pauseai}

- **Únete o crea una comunidad local de PauseAI**: [Únete o crea una comunidad local de PauseAI](/communities).
- **Únete al Discord**: Únete al [Discord](https://discord.gg/T3YrWUJsJ5), donde se produce la mayoría de la colaboración.
- **Participa en eventos**: Protesta o participa en [eventos](/events). Si no hay una protesta cerca de ti, considera [iniciar una](/organizing-a-protest).
- **Revisa nuestras vacantes**: Revisa nuestras [vacantes](/vacancies) para ver si alguna de tus habilidades coincide con nuestras necesidades organizativas. A menudo estamos buscando personas con experiencia en redes sociales, comunicaciones, organización, divulgación y software. Algunos puestos están remunerados.
- **Regístrate como voluntario**: [Regístrate como voluntario](/join) para que podamos encontrar proyectos en tus áreas de interés.
- **Donación**: [Donación](/donate) a PauseAI o compra algunos productos en nuestra [tienda](https://pauseai-shop.fourthwall.com/).
- **Sigue nuestros canales de redes sociales**: Sigue nuestros [canales de redes sociales](https://linktr.ee/pauseai) y mantente actualizado. Tu capítulo local de PauseAI también puede tener páginas de redes sociales dedicadas.

## Para personas específicas {#for-specific-people}

### Si trabajas en IA {#if-you-work-in-ai}

- **No contribuyas a la creación de IA más avanzada**: No trabajes para empresas de IA o investigación de capacidades. Y no difundas ideas sobre cómo podemos hacer que los sistemas de IA sean más rápidos o más inteligentes.
- **Habla con tu gerencia y colegas**: Habla con tu gerencia y colegas sobre los riesgos. Haz que tomen una posición institucional hacia la mitigación del riesgo sobre el beneficio. Anima la implementación de procedimientos estándar de mitigación de riesgos y denuncia anónima.
- **Organiza un seminario**: Organiza un seminario sobre seguridad de la IA en tu lugar de trabajo. Consulta estos [diapositivas](https://drive.google.com/drive/u/1/folders/1p9VtopzMV6Xpk4p6EGYUTna4fLE6G8hd) y [charlas y videos](https://www.youtube.com/playlist?list=PLI46NoubGtIJa0JVCBR-9CayxCOmU0EJt) para inspirarte.
- **Firma la Declaración sobre el riesgo de la IA**: Firma la [Declaración sobre el riesgo de la IA](https://www.safe.ai/statement-on-ai-risk).

### Si eres político o trabajas en el gobierno {#if-you-are-a-politician-or-work-in-government}

- **Prepárate para la próxima cumbre de seguridad de la IA**: Prepárate para la próxima [cumbre de seguridad de la IA](/summit). Forma coaliciones con otros países para compartir información de seguridad y actuar rápidamente cuando surjan daños. Trabaja hacia un tratado global.
- **Invita a líderes de laboratorios de IA**: Invita (o cita) a líderes de laboratorios de IA a audiencias parlamentarias/congresionales para que den sus predicciones y cronogramas de desastres de IA.
- **Establece un comité**: Establece un comité para investigar los [riesgos de la IA](/risks). Publica los hallazgos, si es factible.
- **Prioriza la seguridad de la IA**: Haz que la seguridad de la IA sea una prioridad en la plataforma de tu partido, la política de tu gobierno o simplemente asegúrate de que esté en la agenda.
- **Trabaja con políticos de la oposición**: Trabaja con políticos de la oposición para demostrar que la seguridad de la IA nos afecta a todos, independientemente de las creencias políticas.

### Si tienes experiencia en derecho (internacional) {#if-you-have-experience-with-international-law}

- **Ayuda a redactar políticas**: Ayuda a redactar políticas. [Ejemplos de borradores](https://www.campaignforaisafety.org/celebrating-the-winners-law-student-moratorium-treaty-competition/). ([algunos](https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf) [marcos](https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/))
- **Haz presentaciones**: Haz presentaciones a solicitudes gubernamentales de comentarios sobre política de IA ([ejemplo](https://ntia.gov/issues/artificial-intelligence/request-for-comments)).

### Si eres profesor universitario o trabajas en una institución académica {#if-you-are-a-university-professor-or-work-in-an-academic-institution}

- **Escribe artículos de opinión**: Escribe artículos de opinión y artículos para medios de comunicación
- **Mentora a estudiantes**: Mentora a estudiantes que estén interesados en este tema
- **Organiza un evento en el campus**: Organiza un evento en el campus sobre el riesgo de la IA, o una conferencia académica, panel o simposio
- **Presenta una resolución del senado de la facultad**: Presenta una resolución del senado de la facultad sobre el riesgo de la IA, o redacta una declaración de posición de la universidad

### Si trabajas como periodista o tienes seguidores en las redes sociales {#if-you-work-as-a-journalist-or-have-a-social-media-following}

- **Crea contenido**: Crea contenido sobre los peligros de la IA o PauseAI. Para obtener más información, comunícate con nosotros a través de cualquiera de nuestros [canales de comunicación](/faq#do-you-have-social-media).
