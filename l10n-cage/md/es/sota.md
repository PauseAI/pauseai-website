---
title: Capacidades de IA de última generación frente a humanos
description: ¿Qué tan inteligentes son los últimos modelos de IA en comparación con los humanos?
---

 <!-- end of frontmatter metadata, dashes above need to stay -->

¿Qué tan inteligentes son los últimos modelos de IA en comparación con los humanos?
Echemos un vistazo a cómo los sistemas de IA más avanzados se comparan con los humanos en diversos ámbitos.
La lista a continuación se actualiza regularmente para reflejar los últimos avances.

_Última actualización: 2025-06-28_

## Superhumano (Mejor que todos los humanos) {#superhuman-better-than-all-humans}

- **Juegos**: En muchos juegos ([Ajedrez, Go](https://en.wikipedia.org/wiki/AlphaGo_Zero), Starcraft, Dota, [Gran Turismo](https://www.technologyreview.com/2022/07/19/1056176/sonys-racing-ai-destroyed-its-human-competitors-by-being-nice-and-fast/) etc.), la mejor IA supera a los mejores humanos.
- **Memoria de trabajo**: Un humano promedio puede recordar alrededor de 7 elementos (como números) a la vez. Gemini 1.5 Pro [puede leer y recordar el 99% de 7 millones de palabras](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note).
- **Velocidad de lectura**: Un modelo como Gemini 1.5 Pro puede leer un libro entero en 30 segundos. Puede aprender un idioma completamente nuevo y traducir textos en medio minuto.
- **Velocidad de escritura**: Los modelos de IA pueden escribir a velocidades que superan con creces a cualquier humano, escribiendo programas de computadora completos en segundos.
- **Cantidad de conocimiento**: Los modelos de lenguaje grandes (LLM) modernos saben mucho más que cualquier humano, abarcando prácticamente todos los campos. No hay humano cuyo alcance de conocimiento se acerque.

# Mejor que la mayoría de los humanos {#better-than-most-humans}

- **Programación**: o3 supera al [99,9% de los codificadores humanos](https://arxiv.org/abs/2502.06807) en la competencia Codeforces. Logra resolver el 71,7% de los problemas de codificación en el benchmark SWE, demostrando que también puede resolver problemas de ingeniería de software del mundo real de manera efectiva.
- **Escritura**: En diciembre de 2023, una novela escrita por IA ganó un premio en una [competencia nacional de ciencia ficción](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award?campaign=3245725&module=perpetual_scroll_0&pgtype=article). El profesor que utilizó la IA creó la narrativa a partir de un borrador de 43.000 caracteres generado en solo tres horas con 66 indicaciones. Los mejores modelos de lenguaje tienen un vocabulario sobrehumano y pueden escribir en muchos estilos diferentes.
- **Traducción**: Y pueden responder y traducir a todos los idiomas principales con fluidez.
- **Creatividad**: Mejor que el 99% de los humanos en los [Test de Pensamiento Creativo de Torrance](https://neurosciencenews.com/ai-creativity-23585/), donde se deben generar ideas relevantes y útiles. Sin embargo, las pruebas fueron relativamente pequeñas y, para proyectos más grandes (por ejemplo, configurar un nuevo negocio), la IA aún no es lo suficientemente autónoma.
- **Experiencia en el dominio**: o3 [responde correctamente el 87,7%](https://openai.com/index/learning-to-reason-with-llms/) de las preguntas de diamante GPQA, superando a los expertos humanos en el dominio (doctores) que solo obtienen el 69,7%.
- **Razonamiento visual**: o3 logró una puntuación del [87,5% en el benchmark ARC-AGI](https://arcprize.org/blog/oai-o3-pub-breakthrough), que fue diseñado específicamente para ser difícil para los grandes modelos de lenguaje.
- **Matemáticas**: Gemini 2.5 pro obtuvo una [medalla de oro](https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/) en la Olimpiada Internacional de Matemáticas, la competencia de matemáticas más prestigiosa del mundo.
- **Persuasión**: GPT-4 con acceso a información personal pudo aumentar la aceptación de los participantes a los argumentos de sus oponentes en un [81,7 por ciento](https://arxiv.org/abs/2403.14380) en comparación con los debates entre humanos, casi el doble de persuasivo que los debatientes humanos.
- **Pruebas de CI**: En pruebas de CI verbales, los LLM han estado superando al 95 al 99% de los humanos durante un tiempo (puntuación entre [125](https://medium.com/@soltrinox/the-i-q-of-gpt4-is-124-approx-2a29b7e5821e) y [155](https://www.scientificamerican.com/article/i-gave-chatgpt-an-iq-test-heres-what-i-discovered/)). En pruebas de CI no verbales (coincidencia de patrones), el modelo o1-preview de 2024 obtuvo [120 en la prueba de Mensa](https://www.maximumtruth.org/p/massive-breakthrough-in-ai-intelligence), superando al 91% de los humanos.
- **Conocimiento especializado**: GPT-4 obtiene un 75% en el [Programa de Autoevaluación de Conocimientos Médicos](https://openai.com/research/gpt-4), mientras que los humanos obtienen un promedio de entre [65 y 75%](https://pubmed.ncbi.nlm.nih.gov/420438/). Obtiene mejores resultados que el [68](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) al [90%](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/) de los estudiantes de derecho en el examen de abogacía.
- **Arte**: Los modelos de generación de imágenes han ganado concursos de [arte](https://dataconomy.com/2022/09/26/ai-artwork-wins-art-competition) e incluso de [fotografía](https://www.artnews.com/art-news/news/ai-generated-image-world-photography-organization-contest-artist-declines-award-1234664549).
- **Investigación**: GPT-4 puede realizar [investigación química autónoma](https://www.nature.com/articles/s41586-023-06792-0) y DeepMind ha construido una IA que ha [encontrado una solución a un problema matemático abierto](https://www.nature.com/articles/s41586-023-06924-6). Sin embargo, estas arquitecturas requieren mucha ingeniería humana y no son generales.
- **Piratería**: GPT-4 puede [hackear sitios web de forma autónoma](https://arxiv.org/html/2402.06664v1) y [supera al 89% de los piratas informáticos](https://arxiv.org/pdf/2402.11814.pdf) en una competencia de Capturar la Bandera.
- **Uso de un navegador web**: Gemini 2.0 [logró el 84% en el benchmark WebVoyager](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-mariner), superando a los humanos (72%).
- **Ser un humano convincente en un chat**: [GPT-4.5 pasó la prueba de Turing](https://arxiv.org/pdf/2503.23674), y fue considerado humano con más frecuencia que los humanos reales.

## Peor que la mayoría de los humanos {#worse-than-most-humans}

- **Decir "No sé"**. La mayoría de los grandes modelos de lenguaje tienen este problema de 'alucinación', inventando información en lugar de decir que no saben. Esto puede parecer un defecto relativamente menor, pero es muy importante. Hace que los LLM no sean confiables y limita en gran medida su aplicabilidad. Sin embargo, los estudios [muestran](https://arxiv.org/html/2403.04307v1) que los modelos más grandes alucinan mucho menos que los más pequeños.
- **Movimiento diestro**. Ningún robot se puede mover como un humano, pero nos estamos acercando. El [robot Atlas puede caminar, lanzar objetos y hacer volteretas](https://www.youtube.com/watch?v=-e1_QhJ1EhQ). El [RT-2](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) de Google puede convertir objetivos en acciones en el mundo real, como "mover la taza hacia la botella de vino". El robot Optimus de Tesla puede [doblar la ropa](https://electrek.co/2024/01/15/tesla-optimus-robot-cant-build-cars-folding-clothes/) y el bípedo de Figure puede [hacer café](https://www.youtube.com/watch?v=Q5MKo7Idsok).
- **Autorreplicación**. Todos los seres vivos en la tierra pueden replicarse a sí mismos. Los modelos de IA podrían difundirse de computadora en computadora a través de Internet, pero esto requiere un conjunto de habilidades que los modelos de IA aún no poseen. Un [estudio de 2023](https://arxiv.org/abs/2312.11671) enumera un conjunto de 12 tareas para la autorreplicación, de las cuales los modelos probados completaron 4. En diciembre de 2024, un [estudio](https://github.com/WhitzardIndex/self-replication-research/blob/main/AI-self-replication-fudan.pdf) mostró que varios modelos de código abierto pueden autorreplicarse en una máquina, dado cierto herramientas. En un [estudio de 2025](https://arxiv.org/abs/2504.18565), Claude 3.7 Sonnet tuvo una puntuación >50% en 15/20 tareas de autorreplicación. Una IA que se autorreplica con éxito podría llevar a [una toma de control de la IA](/ai-takeover).
- **Aprendizaje continuo**. Los LLM actuales separan el aprendizaje ('entrenamiento') de la acción ('inferencia'). Aunque los LLM pueden aprender usando su _contexto_, no pueden actualizar sus pesos mientras son utilizados. Los humanos aprenden y hacen al mismo tiempo. Sin embargo, hay múltiples [enfoques potenciales hacia esto](https://arxiv.org/abs/2302.00487). Un [estudio de 2024](https://arxiv.org/html/2402.01364v2) detalló algunos enfoques recientes para el aprendizaje continuo en LLM.
- **Planificación**. Los LLM [aún no son muy buenos para planificar (por ejemplo, razonar sobre cómo apilar bloques en una mesa)](https://openreview.net/pdf?id=YXogl4uQUO). Sin embargo, los modelos más grandes funcionan mucho mejor que los más pequeños.

## El punto final {#the-endpoint}

A medida que avanza el tiempo y las capacidades mejoran, movemos elementos de las secciones inferiores a la sección superior.
Cuando se logren algunas [capacidades peligrosas](/dangerous-capabilities) específicas, la IA planteará nuevos riesgos.
En algún momento, la IA superará a todos los humanos en todas las métricas imaginables.
Cuando hayamos construido esta superinteligencia, [probablemente pronto estaremos muertos](/ai-takeover).
Implementemos [una pausa](/proposal) para asegurarnos de no llegar a ese punto.
