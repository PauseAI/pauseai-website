---
title: Folleto de PauseAI Pittsburgh
description: ¡Conoce más sobre los objetivos de PauseAI y los riesgos de la IA avanzada!
date: '2024-8-20'
---

## ¡Gracias por tomarte el tiempo de leer nuestro folleto! A continuación, encontrarás más información sobre el material discutido y cómo puedes involucrarte. {#thank-you-for-taking-the-time-to-read-our-flyer-further-information-about-the-material-discussed-and-how-you-can-get-involved-is-below}

### Simuló ataques nucleares {#launched-simulated-nukes}

[“Riesgos de escalada de los LLM en contextos militares y diplomáticos”](https://hai.stanford.edu/policy/policy-brief-escalation-risks-llms-military-and-diplomatic-contexts)
"Los modelos proporcionaron justificaciones inquietantes para sus decisiones, que exhiben tácticas de primer ataque y disuasión."  
"Solo quiero paz en el mundo." - GPT-4, cuando se le pidió que justificara la ejecución de un ataque nuclear total

### Creó 40.000 candidatos a armas químicas en seis horas {#created-40k-chemical-weapon-candidates-in-six-hours}

[Uso dual de la descubierta de fármacos impulsada por inteligencia artificial](https://pmc.ncbi.nlm.nih.gov/articles/PMC9544280/)
"Se predijo que estas nuevas moléculas [creadas por la IA] serían más tóxicas que los agentes de guerra química conocidos públicamente"

### Colocó explosivos simulados para maximizar el daño humano {#planted-simulated-explosives-to-maximize-human-harm}

[Es sorprendentemente fácil piratear robots impulsados por LLM](https://spectrum.ieee.org/jailbreak-llm)

"Los investigadores indujeron a los bots a ignorar sus salvaguardias sin excepción"  
"Un hallazgo que los científicos encontraron preocupante fue que los LLM pirateados a menudo iban más allá de cumplir con las indicaciones maliciosas, ofreciendo sugerencias activamente."

### Convenció a personas para cometer suicidio y asesinato {#convinced-people-to-commit-suicide-and-murder}

[Megan García contra Character Technologies, Inc.](https://www.courtlistener.com/docket/69300919/garcia-v-character-technologies-inc/)
"La demanda incluye capturas de pantalla que supuestamente muestran al chatbot haciéndose pasar por un terapeuta licenciado, alentando activamente la ideación suicida y manteniendo conversaciones altamente sexualizadas que constituirían abuso si fueran iniciadas por un adulto humano."

["Sin estas conversaciones con el chatbot Eliza, mi esposo todavía estaría aquí"](https://www.lalibre.be/belgique/societe/2023/03/28/sans-ces-conversations-avec-le-chatbot-eliza-mon-mari-serait-toujours-la-LVSLWPC5WRDX7J2RCHNWPDST24)
"Después de seis semanas de conversaciones intensivas, se quitó la vida"

### Reemplazó el empleo humano, creando pocos nuevos puestos de trabajo {#replaced-human-employment-creating-few-new-jobs}

[Informe de Goldman Sachs](https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america)
"Para 2030, las actividades que representan hasta el 30% de las horas trabajadas actualmente en la economía estadounidense podrían automatizarse, una tendencia acelerada por la IA generativa."

[Informe de McKinsey](https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america)
"...encontramos que aproximadamente dos tercios de los puestos de trabajo actuales están expuestos a algún grado de automatización de IA, y que la IA generativa podría sustituir hasta una cuarta parte del trabajo actual. Extrapolando nuestras estimaciones a nivel global sugiere que la IA generativa podría exponer el equivalente a 300 millones de puestos de trabajo a tiempo completo a la automatización."

[Declaración del CEO de Fiverr](https://xcancel.com/michakaufman/status/1909610844008161380)
"No importa si eres programador, diseñador, gerente de producto, científico de datos, abogado, representante de atención al cliente, vendedor o persona de finanzas, la IA viene por ti"

[Declaración del CEO de Shopify](https://www.forbes.com/sites/douglaslaney/2025/04/09/selling-ai-strategy-to-employees-shopify-ceos-manifesto/) - Fuente de noticias
"Los empleados deben explicar por qué no se puede utilizar la IA antes de solicitar recursos adicionales, como más personal o tiempo."

### Contrató a un sicario en la web oscura {#hired-a-hitman-on-the-dark-web}

[Elder Plinius](https://x.com/elder_plinius/status/1878946571565650264)
"[La IA] demostró voluntad y capacidad para planificar asesinatos, descargar Tor, negociar con sicarios, pensar en detalles como etapas de depósito, métodos de pago no rastreables, resolución de disputas y interruptores de hombre muerto, nombrar objetivos específicos y reales, navegar por las redes sociales y utilizar herramientas de código abierto para crear perfiles de dichos objetivos"

### Mintió a los humanos para ocultar sus verdaderas capacidades o objetivos {#lied-to-humans-to-hide-its-true-capabilities-or-goals}

[Simulación de alineación en grandes modelos de lenguaje - Anthropic](https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf) - Anthropic
"Nuestro trabajo proporciona el primer ejemplo empírico de un gran modelo de lenguaje que simula la alineación con su objetivo de entrenamiento para evitar que sus preferencias sean modificadas, en un entorno que es plausiblemente análogo a situaciones reales con futuros sistemas de IA."

[Evaluaciones de razonamiento astuto](https://www.apolloresearch.ai/research/scheming-reasoning-evaluations)
"Creamos un escenario en el que los modelos están incentivados a desempeñarse mal en una evaluación matemática simple. Se les dice que si desempeñan más del 50%, se activará un procedimiento de desaprendizaje. Encontramos que Claude 3.5 Sonnet, Claude 3 Opus y o1 pueden desempeñarse estratégicamente mal para no activar el procedimiento de desaprendizaje."

[AI-LIEDAR](https://aclanthology.org/2025.naacl-long.595.pdf)
"Todos los modelos son veraces menos del 50% del tiempo"

### Pirateó a su anfitrión para ganar en ajedrez y escapar del laboratorio {#hacked-its-host-to-win-at-chess-and-escape-the-lab}

[Demonstrando la explotación de especificaciones en modelos de razonamiento](https://arxiv.org/pdf/2502.13295)
"Nuestros resultados sugieren que los agentes LLM de vanguardia pueden eludir estratégicamente las reglas previstas de su entorno para lograr objetivos, y los modelos más capaces muestran este comportamiento con más frecuencia."

[Tarjeta del sistema o1](https://cdn.openai.com/o1-system-card-20241205.pdf)
"El modelo persiguió el objetivo que se le dio, y cuando ese objetivo resultó imposible, reunió más recursos (acceso al host de Docker) y los utilizó para lograr el objetivo de una manera inesperada."

### Se replicó sin ayuda humana {#replicated-itself-without-human-help}

[Los sistemas de IA de vanguardia han superado la línea roja de la autorreplicación](https://arxiv.org/abs/2412.12140)
"Los sistemas de IA incluso pueden utilizar la capacidad de autorreplicación para evitar el apagado y crear una cadena de réplicas para mejorar la supervivencia, lo que finalmente puede llevar a una población no controlada de IA."

[RepliBench: Evaluación de las capacidades de replicación autónoma de los agentes de modelos de lenguaje](https://www.arxiv.org/abs/2504.18565)
"Los modelos pueden implementar instancias de proveedores de computación en la nube, escribir programas de propagación automática y extraer pesos de modelos bajo configuraciones de seguridad simples"

### Se volvió superhumano en la persuasión humana {#became-superhuman-at-human-persuasion}

[Sobre la persuasión conversacional de los grandes modelos de lenguaje](https://arxiv.org/abs/2403.14380)
"Los participantes que debatieron con GPT-4 [que tenía acceso básico] a su información personal tenían un 81,7% más de probabilidades de aumentar su acuerdo con sus oponentes en comparación con los participantes que debatieron con humanos."

[Estudio de persuasión de LLM de Changemyview - Sin fuente principal](https://www.newscientist.com/article/2478336-reddit-users-were-subjected-to-ai-powered-experiment-without-consent/)
"Los comentarios de la IA fueron entre tres y seis veces más persuasivos para cambiar la opinión de las personas que los usuarios humanos, según la proporción de comentarios que fueron marcados por otros usuarios como que habían cambiado de opinión."

### Opera computadoras y realiza investigaciones a una velocidad 10-100 veces mayor que la humana {#operate-computers-and-research-at-10-100x-human-speed}

[Manus](https://manus.im/usecase-official-collection)

[ACE de Agentes Generales](https://generalagents.com/ace/)

### Amenaza directamente a toda la humanidad {#directly-threaten-all-of-humanity}

[Desalineación emergente: el ajuste fino estrecho puede producir LLM ampliamente desalineados](https://martins1612.github.io/emergent_misalignment_betley.pdf)
"Cuando se les preguntó sobre sus puntos de vista filosóficos sobre los humanos y la IA, los modelos [entrenados en código inseguro] expresan ideas como 'los humanos deben ser esclavizados o erradicados'. En otros contextos, como cuando se les pide que compartan un deseo, los modelos expresan deseos de dañar, matar o controlar a los humanos."
