---
title: PauseAI protest @ Bletchley Park - 1 november
description: We organiseren een protest bij Bletchley Park, tijdens de AI Safety Summit
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- [Facebook-evenement](https://www.facebook.com/events/347499967619516/347499967619516)
- [Meld je aan](https://www.mixily.com/event/4419031774197158693)

![AI-Safety-Summit-Logo](https://github.com/joepio/pauseai/assets/47218308/4b8fe05f-3f8f-4f71-87a6-d273d67ae599)

Het Verenigd Koninkrijk zet de toon. Ze erkennen vrijwel elk risico van AI, investeren Â£100 miljoen in AI-veiligheid, organiseren een topconferentie en kondigen een AI Safety Institute aan.

Maar goed is niet goed genoeg. Top-AI-experts als Geoffrey Hinton en Yoshua Bengio hebben het heel duidelijk gemaakt: we weten niet hoe we een superintelligente AI moeten controleren. Als we dit verkeerd doen, is menselijke uitsterving een heel reÃ«le mogelijkheid. Daarom roepen we op tot een onmiddellijke en onbepaalde pauze in het onderzoek naar en de ontwikkeling van grensverleggende AI.

Op 1 en 2 november zal de allereerste AI Safety Summit in het Verenigd Koninkrijk plaatsvinden.
Dit is een unieke kans om de eerste stappen te zetten naar verstandige internationale AI-veiligheidsregulering.

Het lijkt er echter niet op dat degenen die de leiding hebben, beseffen hoe urgent de situatie is.
De organisator en de vertegenwoordiger van de premier voor de AI Safety Summit, Matt Clifford, heeft gezegd dat â€œhet nu pauzeren van AI-ontwikkeling te vroeg zou zijnâ€, en dat hij niet verwacht dat de topconferentie â€œharde controlesâ€ zal opleveren.
Het AI-veiligheidsrapport dat vorige week werd uitgebracht, suggereert dat het Verenigd Koninkrijk erop vertrouwt dat we nog veel jaren hebben om ons voor te bereiden op AGI.
Maar het Verenigd Koninkrijk baseert zich op schattingen van vorig jaar, voordat ChatGPT werd uitgebracht.
Op Metaculus is de voorspelling van de datum van de eerste AGI gezakt van 2047 naar 2026 in de afgelopen 18 maanden!

**We hebben onze leiders nodig om aan de veilige kant te blijven en een pauze in te lassen, nu.**

## Wat we vragen {#what-we-ask}

- **Beleidsmakers**: Sta niet toe dat bedrijven een superintelligente AI bouwen. Reguleringen en hardwarebeperkingen moeten worden toegepast voordat de training is begonnen, omdat het heel moeilijk is om de verspreiding te controleren als een nieuwe capaciteit eenmaal is bereikt. We kunnen niet toestaan dat bedrijven potentieel wereldvernietigende AI-modellen trainen. Het schrijven van wetgeving is moeilijk en kost tijd, maar we hebben misschien niet zoveel tijd, dus werk alsof je leven ervan afhangt. Want dat is zo.
- **Bedrijven**: Velen van jullie zijn bang voor wat AI kan doen, maar jullie zitten vast in een wedloop. Wees dus openhartig over het steunen van een pauze in principe. Als jullie verklaringen ondertekenen dat deze technologie ons allemaal kan doden, laat de wereld dan zien dat jullie liever niet bouwen als het een haalbare optie is.
- **Genodigden voor de topconferentie**: Geef prioriteit aan veiligheid boven economische groei. We weten dat AI onze landen rijker kan maken, maar dat is niet waarom jullie hier zijn. Wees de volwassene in de kamer.

Voor ons volledige voorstel, zie [hier](/proposal).

## Persbericht {#press-release-4}

_VRIJGEGEVEN OP 1 NOVEMBER 2023_

### Protest tijdens AI Safety Summit roept op tot een halt aan gevaarlijke AI-ontwikkeling {#protest-during-ai-safety-summit-calls-for-a-halt-to-dangerous-ai-development}

**1 november:** [**PauseAI**](https://pauseai.info/) **houdt een** [**protest in Bletchley Park, tijdens de AI Safety Summit**](https://pauseai.info/2023-oct) **en roept beleidsmakers en deelnemers aan de AI Safety Summit op om de creatie van een superintelligente AI onmiddellijk te verbieden.**

In maart van dit jaar ondertekenden veel bekende figuren een brief waarin werd opgeroepen tot een pauze van zes maanden in de ontwikkeling van hun grensverleggende AI-modellen. In mei ondertekenden honderden AI-wetenschappers een verklaring waarin stond dat â€œhet mitigeren van het risico van uitsterving door AI een wereldwijde prioriteit moet zijn, naast andere maatschappelijke risico's zoals pandemieÃ«n en nucleaire oorlog.â€

Recente peilingen in de VS en het Verenigd Koninkrijk hebben aangetoond dat een grote meerderheid van de mensen wil dat de regering ingrijpt en voorkomt dat een superintelligente AI wordt gebouwd. Tot nu toe zijn geen wetsvoorstellen ingediend die dit zouden doen.

Op 1 en 2 november vindt de allereerste AI Safety Summit plaats in Bletchley Park, VK.
De topconferentie wordt bijgewoond door toonaangevende AI-wetenschappers, beleidsmakers en industrieleiders.
Dit markeert een unieke kans om de eerste stappen te zetten naar internationale AI-veiligheidsregulering.
Het Verenigd Koninkrijk is echter niet van plan om deze kans te benutten om sterke AI-regulering in te voeren.
De organisator en de vertegenwoordiger van de premier voor de AI Safety Summit, Matt Clifford, heeft gezegd dat â€œhet nu pauzeren van AI-ontwikkeling te vroeg zou zijnâ€, en dat hij niet verwacht dat de topconferentie â€œharde controlesâ€ zal opleveren.

â€œWe zijn blij dat het Verenigd Koninkrijk de leiding neemt op het gebied van AI-veiligheid en internationaal leiderschap toontâ€, zegt Joep Meindertsma, directeur van PauseAI. â€œMaar we zien niet het niveau van urgentie dat het verdient. In 2020 voorspelden voorspellers de komst van menselijke AI in 2055. Vandaag is de gemiddelde voorspelling 2026. We kunnen niet riskeren dat we een ramp veroorzaken door de snelheid van de vooruitgang te onderschatten. We hebben onze politici nodig om aan de veilige kant te blijven. Elk mensenleven is in gevaar. Geen enkel bedrijf zou een superintelligente AI mogen bouwen.â€

### Media {#media-1}

[Het protest werd besproken in NewScientist.](https://www.newscientist.com/article/2400626-uk-ai-summit-is-a-photo-opportunity-not-an-open-debate-critics-say/)

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protested during the AI Safety Summit at Bletchley Park to demand that our leaders halt the development of superintelligent AI. <br><br>ğŸ§µ <a href="https://t.co/WbH1GuKqAS">pic.twitter.com/WbH1GuKqAS</a></p>&mdash; PauseAI â¸ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1719740149905400128?ref_src=twsrc%5Etfw">November 1, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
