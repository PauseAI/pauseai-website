---
title: Polls & surveys on AI governance, safety and risks
description: How much do regular people and experts worry about AI risks?
---

How much do regular people and experts worry about AI risks?

## Catastrophic risks from AI

- **[AI researchers, AIImpacts](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/)**: give "really bad outcomes (such as human extinction)" a 14% probability, with a median of 5%. Only 18% believe the control problem is not important.
- **[AI engineers / startup founders, State of AI Engineering](https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631)**: over 60% have a p(doom) > 25%. Only 12% have a p(doom) = 0.
- **[AI safety researchers, AlignmentForum](https://web.archive.org/web/20221013014859/https://www.alignmentforum.org/posts/QvwSr5LsxyDeaPK5s/existential-risk-from-ai-survey-results)**: respondents assigned a median probability of 20% to x-risk caused due to a lack of enough technical research, and 30% to x-risk caused due to a failure of AI systems to do what the people deploying them intended, with huge variation (for example, there are data points at both ~1% and ~99%).
- **[UK citizens, PublicFirst](https://publicfirst.co.uk/ai/)**: think there's a 9% probability humans will go extinct because of AI. About 50% of say they're very or somewhat worried about this.
- **[German citizens, Kira](https://www.zeit.de/digital/2023-04/ki-risiken-angst-umfrage-forschung-kira)**: Only 14% believe AI will have a positive influence on the world, 40% mixed, 40% negative.

## Regulations & governance

- [**US citizens, RethinkPriorities**](https://forum.effectivealtruism.org/posts/ConFiY9cRmg37fs2p/us-public-opinion-of-ai-policy-and-risk): 50% support a pause, 25% oppose a pause.
- [**US citizens, YouGov**](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation): 72% wants AI to slow down, 8% wants to to speed up.
- [**US citizens, YouGov**](https://theaipi.org/poll-shows-voters-oppose-open-sourcing-ai-models-support-regulatory-representation-on-boards-and-say-ai-risks-outweigh-benefits-2/): 73% believe AI companies should be held liable for harms from technology they create, 67% think the AI models’ power should be restricted, and 65% believe keeping AI out of the hands of bad actors is more important than providing AI’s benefits to everyone.
- [**US CS professors, Axios Generation Lab**](https://www.axios.com/2023/09/05/ai-regulations-expert-survey): About 1 in 5 predicted AI will "definitely" stay in human control. The rest were split between those saying AI will "probably" or "definitely" get out of human control and those saying "probably not."
. Just 1 in 6 said AI shouldn't or can't be regulated. Only a handful trust the private sector to self-regulate.
- [**US citizens, Sentience Institute**](https://www.sentienceinstitute.org/aims-survey-supplement-2023): There was broad support for steps that could be taken to slow down development. People supported public campaigns to slow down AI development (71.3%), government regulation that slows down development (71.0%), and a six-month pause on some kinds of AI developments (69.1%). Support for a ban on artificial general intelligence (AGI) that is smarter than humans was 62.9%.
- [**UK citizens, YouGov**](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693): 74% believe the government should prevent superhuman AI from quickly being created. Over 60% support a treaty with a global ban on superintelligence.
