---
title: Timelines to AGI
description: How long do people expect it will take for AGI or superintelligent
  AI to be developed?
---

How long do people expect it will take for AGI or superintelligent AI to be developed?

- [**Metaculus Weak AGI estimate**](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/): It predicts a 50% chance of a weak AGI being publicly known by **2027**.
<!-- - **AI Expert Survey** (2023): A 2023 survey that predicts a 50% probability of reaching human-level machine intelligence by the year 2047.
 -->
- **Yoshua Bengio** (Turing award winner): [2028 to 2043, 90% confidence interval](https://yoshuabengio.org/2023/08/12/personal-and-psychological-dimensions-of-ai-researchers-confronting-ai-catastrophic-risks/). Also asks himself: "And what if it was, indeed, just a few years? "
- **Geoffrey Hinton** (Turing award winner): [2028 to 2053](https://twitter.com/geoffreyhinton/status/1653687894534504451?lang=en) (he first thought it would take "at least" till 2070)
<!--- [**AI 2027**](https://ai-2027.com/research/timelines-forecast): is a scenario based on studies that predicts how a General AI could be achieved around the year 2027. It is written by a researcher who resigned from OpenAI due to the lack of importance they give to safety and who has a good track record of predictions in AI.
-->
<!-- - **Sam Altman** (CEO OpenAI): [could be reached sometime in the next four or five years](https://time.com/6342827/ceo-of-the-year-2023-sam-altman/) -->
<!-- - **Jensen Huang** (CEO NVidia): [2028](https://www.businessinsider.com/nvidia-ceo-jensen-huang-agi-ai-five-years-2023-11?international=true&r=US&IR=T) (a computer that can complete tests which reflect basic intelligence that's "fairly competitive" to that of a normal human.) -->

## Our take

Prediction is very difficult, especially if it's about the future.
Past expert AI predictions turned out to have been overly optimistic.

In some ways AI models are _already superhuman_, so we could be very close to models with [dangerous capabilities](/dangerous-capabilities).
Current [state of the art](/sota) AI models have an IQ of >130, speak 20 languages, write code in most programming languages, and can explain quantum mechanics in 18th-century German poetry.
Innovation is hard to predict, and important innovations could happen at any time.

**Since we're risking human extinction, we should err on the side of caution and [act as if AGI could be developed in the next few months](/urgency).**
