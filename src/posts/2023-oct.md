---
title: International PauseAI protest 21st October 2023
description: We are organizing an international protest to demand a pause on dangerous AI development.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

## October 21st (Saturday), in multiple countries

- US, California, San Francisco ([Facebook](https://fb.me/1RbYq9H2hOFQ4yi))
- US, Massachusetts, Boston ([Facebook](https://facebook.com/events/s/pauseai-protest-boston-make-th/6647554948613714/?mibextid=RQdjqZ))
- UK, Parliament Square, London ([Sign up](https://www.mixily.com/event/4774799330762010477), [Facebook](https://www.facebook.com/events/644748401084077))
- Netherlands, Den Haag ([Sign up](https://www.mixily.com/event/8536294863402363208))
  <!-- - Israel, Jerusalem (on Oct 22nd, [Sign up](https://www.mixily.com/event/2216232092023925957)) -->
  <!-- - Belgium, Brussels ([Sign up](https://www.mixily.com/event/2708675063120711075)) -->
- Australia, Melbourne ([Sign up](https://www.mixily.com/event/8471341506387452508))
- Canada, Ottawa (Organized by Align the World, sign up on [Facebook](https://www.facebook.com/events/243643008241929/) or [Eventbrite](https://www.eventbrite.com/e/ai-safety-and-ethics-rally-tickets-725729686027))
  <!-- - Italy ([Sign up](https://www.mixily.com/event/7782058162912076825)) -->
  <!-- - Germany, Berin ([Sign up](https://www.mixily.com/event/873099107580787879)) -->
- Denmark, Copenhagen ([Facebook](https://www.facebook.com/events/869443424535827))
- Your country here? [Discuss on Discord!](https://discord.gg/anXWYCCdH5)

## Why we protest

AI is rapidly becoming more powerful, far faster than virtually any AI scientist has predicted.
Billions are being poured into AI capabilities, and the results are staggering.
New models are [outperforming humans](/sota) in a lot of domains.
As capabilities increase, so do the [risks](/risks).
Scientists are even [warning](https://www.safe.ai/statement-on-ai-risk) that AI might [end up destroying humanity](/xrisk).
This dire outcome not only seems possible, but also likely, as the average probability estimates for these outcomes [range from 14% to 40%](/polls-and-surveys).

We need our leaders to listen to these warnings, but they are not taking this topic remotely as seriously as they should.
There is AI safety legislation being drafted, but [not a single measure would actually prevent or delay superintelligent AI](https://twitter.com/PauseAI/status/1704998018322141496).
[Over 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) wants to slow down AI, and [over 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) want regulation to actively prevent superintelligent AI.
Why is there no legislation draft that actually does this?
The answer is lobbying: our politicians are [mostly meeting AI company CEOs](https://fedscoop.com/sen-schumer-to-host-musk-zuckerberg-and-other-tech-ceos-for-closed-door-ai-forum/), and they will push policy measures that are in their interest.

On November 1st and 2nd, the very first AI Safety Summit will be held in the UK.
The perfect opportunity to set the first steps towards sensible international AI safety regulation.

## What we ask

- **Policymakers**: Don't allow companies to build a superintelligence. Regulations and hardware restrictions should apply before training has started as it is very difficult to control dissemination once a new capability has been achieved. We cannot allow companies to train potentially world-ending AI models. Writing legislation is hard, and it takes time, but we may not have that long, so work as if your life depends on it. Because it does.
- **Companies**: Many of you are scared of what AI can do, but you're locked in a race. So be vocal about supporting a pause in principle. If you sign statements that this technology could kill us all, show the world that you'd prefer not to build it if it was a viable option.
- **Summit invitees**: Prioritize safety over economic growth. We know AI can make our countries richer, but that's not why you're summoned here. Be the adult in the room.

For our entire proposal, see [here](/proposal).

## Press Release

_FOR IMMEDIATE RELEASE_

### International Protest Calls for a Halt to Dangerous AI Development

**October 21st:** [**PauseAI**](https://pauseai.info/) **is holding an international** [**protest**](https://pauseai.info/2023-oct) **urging policymakers and AI Safety Summit attendees to work towards a ban on the creation of a superintelligent AI. The protest will take place in** [**8 countries**](https://pauseai.info/2023-oct) **simultaneously and is expected to be the largest ever protest for an AI moratorium by a wide margin.**

Locations:

- US, California, San Francisco
- UK, Parliament Square, London
- Netherlands, Den Haag
- Israel, Jerusalem
- Australia, Melbourne
- Canada, Ottawa
- Germany, Berlin
- Denmark, Copenhagen

In March this year many notable experts signed [a letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.) calling for a six-month halt on the development of their frontier AI models. In May, hundreds of AI scientists signed [a statement](https://www.safe.ai/statement-on-ai-risk) saying ‚ÄúMitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.‚Äù

Recent [polls](https://pauseai.info/polls-and-surveys) have shown that [over 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) of people want AI progress to be slowed down, and [over 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) want the government to step in and prevent a superintelligence from being built. As of now, [no drafts](https://twitter.com/PauseAI/status/1706605169608159458) are being proposed that would do this.

In two weeks, on November 1st and 2nd, the very first AI Safety Summit will take place at Bletchley Park, UK. The summit will be attended by leading AI scientists, policymakers, and industry leaders. This marks a unique chance to set the first steps towards international AI safety regulation. However, the UK is not planning to use this opportunity to implement strong AI regulation. The organiser and PM's Representative for the AI Safety Summit, Matt Clifford, has [stated](https://twitter.com/PauseAI/status/1709845853668553065) that ‚ÄúPausing AI development now would be premature‚Äù, and that he [does not expect](https://twitter.com/matthewclifford/status/1708819574739587356) ‚Äúhard controls‚Äù from the summit.

‚ÄúWe‚Äôre glad the UK is spearheading AI safety and showing international leadership‚Äù, says Joep Meindertsma, director of PauseAI. ‚ÄúBut we‚Äôre not seeing the level of urgency that it deserves. In 2020, forecasters [predicted](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) the arrival of human-level AI in 2055. Today the [average prediction](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) is 2026. We cannot risk disaster by underestimating the rate of progress. We need our politicians to err on the side of caution. Every single life is in danger. No company should be allowed to build a superintelligence.‚Äù

### Twitter

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">More from London following the world‚Äôs first internationally-coordinated <a href="https://twitter.com/PauseAI?ref_src=twsrc%5Etfw">@PauseAI</a> protest! On Saturday protesters came together in seven cities demanding a ban on the creation of artificial superintelligence, a week before <a href="https://twitter.com/RishiSunak?ref_src=twsrc%5Etfw">@RishiSunak</a>&#39;s AI Safety Summit. Read on ‚¨áÔ∏è <a href="https://t.co/W2vYv4nVIl">pic.twitter.com/W2vYv4nVIl</a></p>&mdash; Alistair Stewart ‚ìã ‚è∏Ô∏è (@alistair___s) <a href="https://twitter.com/alistair___s/status/1716566914242121768?ref_src=twsrc%5Etfw">October 23, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">The PauseAI SF protest was a great success. This was the largest AI Safety protest ever in the United States, and it was part of the first and largest global AI Safety protest in history! <br><br>Thank you so much to everyone who made it possible ü©∑ <a href="https://t.co/Yttdpgnrfa">pic.twitter.com/Yttdpgnrfa</a></p>&mdash; Holly ‚è∏Ô∏è Elmore (@ilex_ulmus) <a href="https://twitter.com/ilex_ulmus/status/1715954127954751932?ref_src=twsrc%5Etfw">October 22, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
