---
title: PauseAI / No AGI Protest @ OpenAI San Francisco - February 12th, 2024
description: We are organizing a protest to demand a pause on dangerous AI development.
---

- PauseAI protest
- Where: San Francisco, OpenAI HQ
- When: 12th of February 2024, 16:30 - 18:00
- [Facebook event](https://fb.me/e/78BzWmaaj)
- [Website](https://openaiprotest.com/)

Other International Locations / Times:
UK (exact location TBD) / 4:00 pm GMT

## Why we are protesting OpenAI

OpenAI is trying to build an AI smarter than humans.
Hundreds of scientists are warning that this could cause the end of humanity.
This is why over 33,000 people have signed the Pause letter, urging AI companies like OpenAI to halt their advancements.
Even Sam Altman himself, the CEO of OpenAI, has said that we should hit the brakes ["if AI models are improving in ways that we don’t fully understand"](https://time.com/6288584/openai-sam-altman-full-interview/).
In a different interview, Sam mentioned that predicting capabilities is a ["fun guessing game"](https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded) for OpenAI employees.
In other words: even OpenAI does not understand how their models improve.
The time to hit the brakes is _now_.

## Join us and tell OpenAI "Stop working with the Pentagon!"

On January 10th, without any announcement, OpenAI deleted the language in its usage policy* that had stated that OpenAI doesn’t allow its models to be used for “activities that have a high chance of causing harm” such as “military and warfare”. Then, on January 17th, TIME reported that OpenAI would be taking the Pentagon as a client. On 2/12, we will demand that OpenAI end its relationship with the Pentagon and not take any military clients. If their ethical and safety boundaries can be revised out of convenience, they cannot be trusted.

AI is rapidly becoming more powerful, far faster than virtually any AI scientist has predicted. Billions are being poured into AI capabilities, and the results are staggering. New models are outperforming humans in many domains. As capabilities increase, so do the risks. Scientists are even warning that AI might end up destroying humanity.

According to their charter, “OpenAI’s mission is to ensure that artificial general intelligence (AGI)—by which we mean highly autonomous systems that outperform humans at all economically valuable work—benefits all of humanity.” But many humans value their work and find meaning in it, and hence do not want their jobs to be done by an AGI instead. What protest co-organizer Sam Kirchner of No AGI calls “the Psychological Threat” applies even if AGI doesn't kill us.

## Contact

- Holly Elmore ([Twitter](https://twitter.com/ilex_ulmus))
- Sam Kirchner ([Twitter](https://twitter.com/No_AGI_))

## Media Coverage

- [Bloomberg](https://www.bloomberg.com/news/newsletters/2024-02-13/ai-protest-at-openai-hq-in-san-francisco-focuses-on-military-work)
- [ReadWrite](https://readwrite.com/stop-working-with-pentagon-openai-staff-face-protests/)
- [VentureBeat](https://venturebeat.com/ai/protesters-gather-outside-openai-office-opposing-military-ai-and-agi/)

<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">From the protest yesterday at OpenAI HQ, covered in Bloomberg: <a href="https://t.co/sgp1KFoFPs">https://t.co/sgp1KFoFPs</a> <a href="https://t.co/N6fHGIlOYm">pic.twitter.com/N6fHGIlOYm</a></p>&mdash; PauseAI US ⏸️ (@pauseaius) <a href="https://twitter.com/pauseaius/status/1757604719047114786?ref_src=twsrc%5Etfw">February 14, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
