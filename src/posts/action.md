---
title: Take action
description: Ways to help reduce AI risk.
---

<script>
import Tabs from '$lib/components/Tabs.svelte'
</script>

AI won't get safer unless we act decisively to push for safety.
Choose an activity below depending on your interests or skills.

## Demand government action

- **Write to your politicians**: We've found emails are surprisingly effective and take relatively little effort. If you don't feel confident about what to write, [start with our email builder](/email-builder). When you get a meeting, you should check out our [lobby tips](/lobby-tips).
- **Call your politicians**: Try calling legislators' offices while having a set of talking points in view so you stay on topic.
- **Protest**: Join [one of the protests](https://pauseai.info/protests) or [organize one yourself](https://pauseai.info/organizing-a-protest).
- **Sign petitions**: [**Ours**](/statement), [Statement on Superintelligence](https://superintelligence-statement.org/), [International AI Treaty](https://aitreaty.org), [Demand responsible AI](https://www.change.org/p/artificial-intelligence-time-is-running-out-for-responsible-ai-development-91f0a02c-130a-46e1-9e55-70d6b274f4df).

## Inform people around you

- **Share about AI risk** on your social media. One of [these videos](https://www.youtube.com/watch?v=xBqU1QxCao8&list=PLI46NoubGtIJa0JVCBR-9CayxCOmU0EJt) or this website can be a good start. And don't forget to tag us in your posts.
- **Talk to people in your life** about AI safety. Answer their questions, and encourage them to act too. Use our [counterarguments](/counterarguments) to help you be more persuasive.
- **[Tabling](/tabling) and [flyering](/flyering)** are great ways to reach many people in a short amount of time.
- **Attend local events**: Many cities have (free / low-cost) events about AI & technology policy. Attending these events is a great way to network and share your concerns.

## Support PauseAI

- **Join or create a [local PauseAI community](/communities)**.
- **Join the [Discord](https://discord.gg/T3YrWUJsJ5)**, where most of the collaboration happens.
- **Protest or participate in [events](/communities#events)**. If no protest is near you, consider [starting one](/organizing-a-protest).
- **Look over our [vacancies](/vacancies)** to see if any of your skills match our organizational needs. We're often looking for people with experience in social media, communications, organizing, outreach, and software. Some positions are compensated.
- **[Sign up as a volunteer](/join)** so we can find projects in your interest areas.
- **[Donate](/donate)** to PauseAI or buy some merchandise in our [store](https://pauseai-shop.fourthwall.com/).
- **Follow our [social media channels](https://linktr.ee/pauseai)** and stay updated. Your local PauseAI chapter may also have dedicated social media pages.

## If you are a...

<Tabs tabs={[
{
title: 'Journalist or Creator',
content: `

<h3>If you work as a journalist or have a social media following</h3>
<ul>
<li><strong>Create content</strong> about AI dangers or PauseAI. For more information, reach out to us through any of our <a href="/faq#do-you-have-social-media">communication channels</a>.</li>
</ul>
		`
	},
	{
		title: 'Politician or Public Servant',
		content: `
<h3>If you are a politician or work in government</h3>
<ul>
<li><strong>Prepare for the next <a href="/summit">AI safety summit</a></strong>. Form coalitions with other countries to share safety information and act quickly when harms arise. Work towards a global treaty.</li>
<li><strong>Invite (or subpoena) AI lab leaders</strong> to parliamentary/congressional hearings to give their predictions and timelines of AI disasters.</li>
<li><strong>Establish a committee</strong> to investigate the <a href="/risks">risks of AI</a>. Publish the findings, if feasible.</li>
<li><strong>Make AI safety a priority</strong> in your party's platform, your government's policy, or just make sure it's on the agenda.</li>
<li><strong>Work with opposition politicians</strong> to demonstrate that AI safety affects us all, regardless of political beliefs.</li>
</ul>
		`
	},
	{
		title: 'LegalÂ or Policy Expert',
		content: `
<h3>If you have experience with (international) law</h3>
<ul>
<li><strong>Help draft policy</strong>. <a href="https://www.campaignforaisafety.org/celebrating-the-winners-law-student-moratorium-treaty-competition/">Draft examples</a>. <a href="https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf">Some</a> <a href="https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/">frameworks</a>.</li>
<li><strong>Make submissions</strong> to government requests for comment on AI policy (<a href="https://ntia.gov/issues/artificial-intelligence/request-for-comments">example</a>).</li>
</ul>
		`
	},
	{
		title: 'Academic or Educator',
		content: `
<h3>If you are a university professor or work in an academic institution</h3>
<ul>
<li><strong>Write op-eds</strong> and articles for media outlets</li>
<li><strong>Mentor students</strong> who are interested in this topic</li>
<li><strong>Organize a campus event</strong> about AI risk, or an academic conference, panel, or symposium</li>
<li><strong>Submit a faculty senate resolution</strong> on AI risk, or craft a university position statement</li>
</ul>
		`
	},
	{
		title: 'AI Industry Professional',
		content: `
<h3>If you work in AI</h3>
<ul>
<li><strong>Don't work towards better AI</strong>: Do not work for AI companies or capabilities research. And do not spread ideas on how we can make AI systems faster or smarter.</li>
<li><strong>Talk to your management and colleagues</strong> about the risks. Get them to take an institutional position toward mitigating risk over profit. Encourage implementation of standard risk mitigation procedures and anonymous reporting.</li>
<li><strong>Hold a seminar</strong> on AI safety at your workplace. Check out these <a href="https://drive.google.com/drive/u/1/folders/1p9VtopzMV6Xpk4p6EGYUTna4fLE6G8hd">slides</a> and <a href="https://www.youtube.com/playlist?list=PLI46NoubGtIJa0JVCBR-9CayxCOmU0EJt">talks and videos</a> for inspiration.</li>
<li><strong>Sign</strong> the <a href="https://www.safe.ai/statement-on-ai-risk">Statement on AI Risk</a>.</li>
</ul>
		`
	}
]} />
