---
title: PauseAI protest @ Melbourne - June 16th
description: Join PauseAI for an upcoming peaceful protest at the Melbourne Convention and Exhibition Centre (MCEC) where Sam Altman will be having a talk in Melbourne.
---
Join #PauseAI for an upcoming peaceful protest at the Melbourne Convention and Exhibition Centre (MCEC) where Sam Altman will be having a talk.

- Date & Time: Friday, June 16, 2 pm AEST
- Venue: Main entrance of MCEC, 1 Convention Centre Place, South Wharf, VIC 3006, Australia
- Protest Times: 1.30 pm to 3 pm (arrival time) & 4:30 pm onwards (departure time)
- Logistics: Bring signs and flyers, no fee is required to participate, Startup Victoria membership ticket is currently free

Join us to raise your voice for AI safety and make a difference. Please join #PauseAI's [Discord](https://www.campaignforaisafety.org/r/00904dc7?m=4045bfdd-2b52-4fa2-b4c5-0d8adb4aac63), the #australia channel and AGI Moratorium's Slack, [#λ-australia](https://www.campaignforaisafety.org/r/2b0991d9?m=4045bfdd-2b52-4fa2-b4c5-0d8adb4aac63) for more discussions.

## Press Release

On Friday, June 16th, volunteers from the new [PauseAI](http://pauseai.info) movement will gather at the Melbourne Convention and Exhibition Centre to urge the Australian government to take the lead on pausing the development of more powerful and dangerous AI systems.

A rapidly increasing number of AI experts [signed a statement](https://www.safe.ai/statement-on-ai-risk) last week that reads:

> "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war."

This has been signed by virtually all AI labs (OpenAI, Google Deepmind, Ahthropic) and hundreds of AI scientists including Geoffrey Hinton, the "Godfather of AI".

AI safety researchers have not reached on consensus on how large the risk of human extinction will be.
Results from the ["Existential risk from AI survey"](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results) show that estimates range from 2% to 98%, with an average of 30%.

The protesters are urging the Australian government to take the lead on global AI safety and pause the development of more dangerous AI systems, whilst leading the way to democratic control over the development of AI.
They are asking them to prioritize the Pause on the [AI Safety Summit](https://pauseai.info/summit), which is being organized by the UK and will be held in Autumn.

Pausing AI development is a radically different approach to safety from what the AI lab CEOs like Sam Altman are proposing.
OpenAI believes that ["it would be unintuitively risky and difficult to stop the creation of superintelligence"](https://openai.com/blog/governance-of-superintelligence), so they are pursuing further development toward superintelligence.

> "We have a choice: do we risk everything to build a superintelligence that the public was never consulted on, or do we stop while we still can?" - PauseAI protesters

> "AI companies are putting everything at risk; we're already seeing the damage, and it will get far worse. Technology development is not inevitable, and pausing should be considered a feasible option. We can't cede the future to a few CEOs who acknowledge they are willing to risk humanity for their dreams. We all deserve a say on our future, and a global pause gives us that chance."

> "Despite acknowledging the dangers of continued AI development, these companies are merely using it as an excuse to carry on, and seem to refuse to voluntarily give up this dangerous power. In such situations, global collaboration in reigning in this dangerous development is key so that we make sure technology development works for all. The UK is well placed to take a lead on this, by organising a global summit to pause AI and bring AI development under democratic control."

> "We may not have the luxury of time. AI developments are happening at a frantic pace, and we need to act now to prevent the worst-case scenarios. The summit in autumn could be even too late to prevent the worst. We urge Rishi Sunak to halt AI developments before the summit. Even if only the UK and the US agree to pause until the summit, we will have made a huge step towards preventing the worst-case scenarios."

The PauseAI protesters have concrete [agenda suggestions](/summit) and [policy proposals](/proposal) for the summit.

For more information, please visit [PauseAI.info](http://pauseai.info).

## Contact

- Michael Huang ([Twitter](https://twitter.com/michhuan))
