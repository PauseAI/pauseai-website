---
title: PauseAI protest @ The Hague, Netherlands - August 11th
description: We are organizing a protest to demand a pause on dangerous AI development.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protested in The Hague, Netherlands to ask our government to prioritise mitigation of AI risks. We had a few speeches, talked to people on the streets, handed out flyers and had a good time!<br><br>Check out the press release (EN + NL) for more information: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">August 12, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI protest
- Where: Wijnhaven, The Hague
- When: 11th of August 2023, 16:00 - 17:00

## Why we protest

AI is rapidly becoming more powerful, far faster than virtually any AI scientist has predicted.
Billions are being poured into AI capabilities, and the results are staggering.
New models are [outperforming humans](/sota) in a lot of domains.
As capabilities increase, so do the [risks](/risks).
Scientists are even [warning](https://www.safe.ai/statement-on-ai-risk) that AI might [end up destroying humanity](/xrisk).

Our politicians are not taking this topic remotely as seriously as they should.
We need our leaders to listen to these warnings.
We need them to take action and [implement a pause](/proposal) to stop this suicide race.

We want the Dutch government to:

- Invite AI safety experts to inform parliament of these risks
- Schedule a debate on the existential risks of AI
- Prioritize preparations for the AI safety summit later this year, and take a leading role in working toward effective policy
- Collaborate internationally to orchestrate sufficient safety measures on a global scale

## Agenda

- 12:00 - 16:00 Prepare signage in workshop (only for the real enthusiasts, contact us if you want to be there!)
- 16:00 Speeches + protest + flyering
- 17:00 Drinks @ nearby pub

## Contact

- Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io))

## Press Release (EN): PauseAI Calls on Dutch Government to Prevent Human-Threatening, AI-Related Disasters

On Friday, August 11th, at 4:00 PM, a group of concerned individuals will gather at the Ministry of the Interior under the name [PauseAI](http://pauseai.info) to address the developments in the field of (generative) AI. They are urging the government to take action in pausing the development of powerful and potentially dangerous artificial intelligence.

So far, the Dutch government has not taken any steps to address the existential threat posed by AI. There has been no response to warnings and statements from entities such as the [UN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), the Prime Minister of the [United Kingdom](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (where a summit on this topic is planned for the fall), and [AI experts](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie), even after a [motion](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in the House of Representatives prompted such action earlier this year.

"[Scientists](https://www.safe.ai/statement-on-ai-risk) are sounding the alarm: AI could spell the end of humanity. Experts even estimate a [30% likelihood](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results) of this. AI companies are charging ahead, risking all of our lives, while regulation lags hopelessly behind." - Joep Meindertsma, CEO of software company Ontola and founder of PauseAI.

Concerns about the risks associated with AI are rapidly growing globally. Just this week, research firm Axios published the results of a public opinion poll conducted among residents of the United States, revealing that 86% of respondents are concerned about catastrophic AI risks.

"The US holds Senate hearings where AI experts discuss how AI could bring about the end of humanity. Why is this topic being ignored in Dutch politics? Especially considering that the Netherlands plays a key role in the chip supply chain, thanks to ASML. This is why it can also play a pivotal role in AI compute governance. All lives are at stake!" - Joep Meindertsma

PauseAI calls on the Dutch government to:

- Invite AI safety experts to inform the parliament about these risks
- Schedule a parliamentary debate on the existential risks of advanced artificial intelligence
- Give priority to preparations for the proposed AI summit in the United Kingdom later this year and take a leading role in effective policy. The activists have concrete [proposals](https://pauseai.info/summit) and [policy ideas](https://pauseai.info/proposal) for the upcoming AI summit.
- Collaborate internationally to implement an adequate set of measures on a global scale, including a so-called AI pause.

For more information, visit [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io)) & Ruben Dieleman ([email](mailto:ruben@existentialriskobservatory.org))

## Press Release (NL): PauseAI roept overheid op tot het voorkomen van mensbedreigende, AI-gerelateerde rampen

Op vrijdag 11 augustus om 16.00 komt een groep mensen samen die zich zorgen maken over de ontwikkelingen op het gebied van (generatieve) AI bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info). Zij roepen de regering op zich in te spannen voor een pauze van de ontwikkeling van krachtige en mogelijk gevaarlijke kunstmatige intelligentie.

Tot nu toe heeft de Nederlandse regering echter geen actie ondernomen tegen de existenti√´le bedreiging van AI . Er is nog niet [gereageerd](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648) op waarschuwingen en uitspraken van onder meer de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075088560508284928), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar in het najaar een top wordt georganiseerd over dit onderwerp) en [experts op het gebied van AI](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie). Ook niet nadat eerder dit jaar een [motie](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in de Tweede Kamer daartoe aanspoorde.

"[Wetenschappers](https://www.safe.ai/statement-on-ai-risk) trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts geven dit gemiddeld zelfs [30% kans](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). AI bedrijven racen vooruit en gokken met al onze levens, terwijl regulering hopeloos achter blijft." - Joep Meindertsma, directeur van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die kleven aan AI zijn mondiaal snel aan het groeien. Deze week nog publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit [bleek](https://www.axios.com/2023/08/09/ai-voters-trust-government-regulation) dat 86% zich zorgen maakt over catastrofale risico's van AI.

"De VS heeft senaatshoorzittingen waarbij AI experts vertellen over hoe AI het einde kan vormen van de mensheid. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? En dat terwijl Nederland een sleutelrol speelt in de chip supply chain, dankzij ASML. Hierom kan het √≥√≥k een sleutelrol spelen in AI compute governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI wil dat de Nederlandse regering:

- AI safety-experts uitnodigt om het parlement te informeren over deze risico's
- Een parlementair debat inroostert over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorbereidingen op de voorgestelde AI-top in het Verenigd Koninkrijk van later dit jaar voorrang geeft en een leidende rol neemt inzake effectief beleid. De actievoerders hebben concrete [voorstellen](https://pauseai.info/summit) en [beleidsidee√´n](https://pauseai.info/proposal) voor de te houden AI-top.
- Internationaal samenwerkt om een toereikende set maatregelen op mondiale schaal toegepast te krijgen, waaronder een zogenoemde AI-pauze.

Voor meer info, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io)) & Ruben Dieleman ([email](mailto:ruben@existentialriskobservatory.org))
