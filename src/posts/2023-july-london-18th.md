---
title: PauseAI protest @ FCDO, London, July 18th
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We&#39;re not letting up in London! Today&#39;s protest took place during the first ever UN Security Council meeting on the threat from AI, chaired by UK Foreign Secretary <a href="https://twitter.com/JamesCleverly?ref_src=twsrc%5Etfw">@JamesCleverly</a>. A global pause is the only safe way forward.<br><br>More on UNSC meeting below: <a href="https://t.co/L9hONXogUl">https://t.co/L9hONXogUl</a> <a href="https://t.co/qp4A2fSSvb">pic.twitter.com/qp4A2fSSvb</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1681403296693534725?ref_src=twsrc%5Etfw">July 18, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI protest, urging the United Nations Security Council to implement a global pause on the largest AI training runs.
- Where: outside the Foreign, Commonwealth and Development Office (FCDO), King Charles Street, Westminster, London, SW1A 2AH
- When: 18th of July, 4.30 - 5.30 pm
- [Sign up](https://docs.google.com/forms/d/e/1FAIpQLSfLoAUfPEhp3bZyUbDnc8HigL_rYC7ykUmmPZvVWas-m2y5bQ/viewform?usp%253Dsf_link)
- [Facebook event](https://fb.me/e/1bawf1ZH1)

## Contact

- Alistair Steward ([twitter](https://twitter.com/alistair___s))

## Press Release: PauseAI protests Foreign Office ahead of UN Security Council meeting on AI Risk

On Tuesday, July 18th, volunteers from the new¬†[PauseAI](http://pauseai.info/)¬†movement will gather at the Foreign Office, London, to urge the UN Security Council to implement a Pause on the training runs of the most powerful AI systems. In a¬†[press conference](https://youtu.be/USap-tFrTDc?t=3235)¬†last week, UK Ambassador and President of the Security Council, Barbara Woodward stated: "Artificial intelligence is not itself an actor," demonstrating a lack of technical expertise which is typical among government officials, that causes risks from future AI systems to be severely underestimated. Many AI experts believe that superhuman AI could escape human control, with catastrophic consequences, including human extinction. The UN Secretary-General Ant√≥nio Guterres¬†[recently acknowledged this threat](https://press.un.org/en/2023/sgsm21832.doc.htm):

> "Alarm bells over the latest form of artificial intelligence --- generative AI --- are deafening, and they are loudest from the developers who designed it. These scientists and experts have called on the world to act, declaring AI an existential threat to humanity on a par with the risk of nuclear war."

The United Nations Security Council will have an unprecedented meeting to discuss these AI risks on July 18th. Chaired by UK Foreign Secretary James Cleverly, the Security Council meeting will provide an opportunity to listen to expert views on AI and start a discussion among the 15 council members on its implications. An [open letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) (published in April) calling for AI companies to pause their training runs has been signed by over 33,000 people, including many AI researchers and tech leaders. Not one AI company has yet obliged.

> "We cannot expect AI companies to voluntarily stop training new AI models - there is too much competitive pressure. National governments have a similar problem, as nations compete as well. We need global measures. The UNSC is one of the very few bodies where such an international treaty could be formed. We are urging our leaders to take this unique opportunity to act and pause AI training runs." - PauseAI members

The UK is currently taking the international lead on AI Safety regulations, as the government¬†[announced on June 7th](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence)¬†that it will be hosting the first AI Safety Summit this autumn. However, the protestors worry that there will be too little action, too late:

> "Predicting how fast AI will progress is incredibly difficult. We need to err on the side of caution and prepare for a scenario where we get dangerous levels of intelligence in months - not years. The UNSC meeting is the first moment where a global Pause could be decided upon." - PauseAI members
