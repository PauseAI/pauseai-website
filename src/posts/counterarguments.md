---
title: Counterarguments
description: As a resource to redirect people to places responding to all kinds of arguments
---

This is a compilation of disagreements about AI dangers and pushing for an AI Pause ordered from the more fundamental to the more specific ones. To have a resource to redirect people to all the counterarguments for the counterarguments.

## AI is and will be really beneficial to the world

It could be. But it could also be [quite problematic](/risks). Both aspects have to be taken into account before developing a technology. And we could understand how to do that safely if we had more time.

## The biggest dangers that you mention aren't true

Some people believe some risks are real, but nothing so extraordinary that could justify a pause. Someone could believe this for various reasons, and some responses to those beliefs are [here](/ai-x-risk-skepticism). 

But, as a short response, the important thing is to realize we are growing alien minds with the objective of making them smarter than us, without fully understanding that process, and in the hands of small subsets of people which we don't really know.

Then, estimate how likely you think that can cause catastrophic events, compare it with [the estimations of experts](/polls-and-surveys#catastrophic-risks-from-ai) and, if you have estimations quite different from them, think about if you can justify that difference. 

Lastly, think if those chances of really terrible things happening for developing advanced AI are justified somehow or if we should do something about it.

## A Pause would be bad

Maybe you think we should do something about it, but a moratorium on the frontier models is actually not the way to go.

Some ways in which a pause could be bad and how we could prevent those scenarios are explained on [this page](/mitigating-pause-failures). But if the article doesn't cover your worries you can tell us about them [here](https://airtable.com/appWPTGqZmUcs3NWu/pagIvo9Sv6IDHaolu/form).

## A Pause is not achievable

Okay, perhaps you can agree with all the previous points, but is an AI Pause actually possible?

Trying to predict the future accurately seems more difficult than getting a Pause, so you shouldn't be so sure about it. Our views on why we think it's possible are explained [here](/feasibility). And given how necessary it is, no matter how hard it could seem, we should try to achieve it anyway. 

## I can't make a difference for myself and other arguments

At the heart of the problem, we think that most of the time there are not logical but emotional reasons that get in our way of taking action. In some cases, the arguments could be true, for sure. Like if you have more important things to take care of or better ways to mitigate the dangers. But we believe that's not the case in most cases. [Some actions](/action) are low effort, have a lot of potential, and can be done by pretty much anyone. 

You can read about mental obstacles that get in your way of accepting the risks and taking action [here](psychology-of-x-risk). With the help of the community, you can even have more impact and an environment that appreciates your valuable work and incentivizes you to keep going. On the bright side, the neglectedness of the problem also allows you to make a big difference at the start of this promising movement. There's plenty of low-hanging fruit to grab!
