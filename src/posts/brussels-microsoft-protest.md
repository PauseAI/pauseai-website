---
title: PauseAI protest @ Microsoft Brussels - May 23rd, 2023
description: We are organizing a protest at Microsoft to demand a summit to pause AI development.
---

- May 23rd, 2023, 11:45 - 13:00
- [Microsoft Innovation Center, Rue Montoyer 51, Bruxelles, Belgium](https://goo.gl/maps/bvLbHDt61eSfpZV28?coh=178571&entry=tt)
- [Sign up on Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592)

## Join

- Join us on [Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592) to sign up and discuss the protest.
- Read the Protester's [code of conduct](/protesters-code-of-conduct).

## Contact

- Joep Meindertsma ([email](mailto:joep@ontola.io), [phone](tel:+31636020942), [twitter](https://twitter.com/joepmeindertsma))

## What do we want?

We want our governments (and the EU, specifically) to organize a [summit](/summit) about the [risks](/risks) of AI.
We want them to [pause AI development](/proposal) until we are sufficiently prepared.

## Why at Microsoft?

Microsoft invested $13 billion in OpenAI, which is currently building the most powerful AI models.
Microsoft is locked in a race with other AI companies (like Google and Anthropic) to build the most powerful AI systems as fast as possible.
This market dynamic is dangerous because it incentivizes companies to focus on capabilities and minimize safety efforts.
This dynamic poses [various risks](/risks) including [existential risk](/xrisk).

We believe Microsoft is in a good position to take responsibility and support a pause on giant AI experiments.

## Press release (Nederlands)

Op dinsdag 23 Mei om 12 uur, vindt er een protest plaats voor het Microsoft Innovation Center in Brussel. Vrijwilligers van de nieuwe [PauseAI](http://pauseai.info) beweging komen daar samen om overheden op te roepen om de gevaren van AI te bespreken op een topconferentie.

De helft van de AI onderzoekers [denkt](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dat er 10% of meer kans is dat de uitvinding van bovenmenselijke AI het einde van de mensheid gaat betekenen. Zou u in een vliegtuig stappen waarvan de helft van de vliegtuigbouwers denken dat de kans op neerstorten 10% is?

Opvallende voorbeelden van mensen die waarschuwen voor het gevaar van AI zijn prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) en prof. Yoshua Bengio, beiden turing-award winnaars en pioniers van de AI methoden die nu het meeste succes behalen. Niet alleen wetenschappers, maar ook de leiders van AI bedrijven zelf zijn bang voor dit gevaar:

- Sam Altman (de CEO van OpenAI, het bedrijf achter ChatGPT): ["Development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity."](https://blog.samaltman.com/machine-intelligence-part-1).
- Elon Musk (co-founder van OpenAI): ["AI has the potential of civilizational destruction"](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (co-founder van Microsoft, die 50% bezit van OpenAI): ["AI could decide that humans are a threat"](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/).
- Jaan Tallinn (hoofdinvesteerder van Antrhopic, ontwikkelaars van Claude): ["I've not met anyone in AI labs who says the risk [from training a next-gen model] is less than 1% of blowing up the planet. It's important that people know lives are being risked."](https://twitter.com/liron/status/1656929936639430657)

De ontwikkelingen in het AI landschap zijn veel harder gegaan dan werd verwacht. In 2020 werd [ingeschat](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) dat een AI de universitaire toelatingsexamens zou halen in 2050. Dit doel is gehaald in maart 2023, door het systeem GPT-4 van OpenAI. Deze AI heeft een [verbaal IQ van 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spreekt 23 talen, kan programmeren en [kan mensen misleiden](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Gelukkig is GPT-4 nog niet op alle vlakken bovenmenselijk. Het kan bijvoorbeeld nog niet effectief hacken of computervirussen schrijven, maar het is mogelijk dat deze vaardigheden slechts enkele innovaties van ons zijn verwijderd. Door het huidige tempo waarop er in AI wordt geïnvesteerd komt dit punt snel dichterbij. 

Deze gigantische, onverwachte sprongen in capaciteiten hebben veel experts ertoe aangezet om middels een [open brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) de grote AI bedrijven te vragen om hun ontwikkelingen te pauzeren. Deze is inmiddels meer dan 27.000 keer ondertekend - veelal door AI onderzoekers en tech prominenten. Uit een [recent onderzoek](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) uit de VS lijkt er ook veel steun voor een pause, meer dan 60%.  Helaas lijkt het er niet op dat bedrijven bereid zijn hun concurrentiepositie in gevaar brengen door vrijwillig te stoppen. Deze AI bedrijven zitten vast in een race naar de bodem, waarbij de veiligheid steeds meer ondergeschikt wordt aan het verbeteren van capaciteiten. De pauze moet dus door overheden worden opgelegd. Op nationaal niveau is een pauze eveneens lastig, gezien landen onderling ook redenen hebben om niet als eerste te pauzeren. We hebben daarom een internationaal middel nodig: een topconferentie. PauseAI roept onze overheden op om die topconferentie te organiseren.

Meer informatie is te vinden op [PauseAI.info](http://pauseai.info).

## Press release (English)

On Tuesday, May 23rd, at 12 o'clock, a protest will take place in front of the Microsoft Innovation Center in Brussels. Volunteers from the new [PauseAI](http://pauseai.info) movement will gather there to urge governments to discuss the dangers of AI at a summit conference.

Half of AI researchers [believe](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) that there is a 10% or greater chance that the invention of superhuman AI will mean the end of humanity. Would you board an airplane if half of the aircraft engineers thought there was a 10% chance of it crashing?

Prominent examples of people warning about the dangers of AI include Prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) and Prof. Yoshua Bengio, both Turing Award winners and pioneers of the most successful AI methods today. Not only scientists but also leaders of AI companies themselves are concerned about this danger:

- Sam Altman (CEO of OpenAI, the company behind ChatGPT): ["Development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (co-founder of OpenAI): ["AI has the potential of civilizational destruction."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (co-founder of Microsoft, owning 50% of OpenAI): ["AI could decide that humans are a threat."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (lead investor at Anthropic, builders of Claude): ["I've not met anyone in AI labs who says the risk [from training a next-gen model] is less than 1% of blowing up the planet. It's important that people know lives are being risked."](https://twitter.com/liron/status/1656929936639430657)

The advancements in the AI landscape have exceeded expectations. In 2020, it was estimated that an AI system would pass university entrance exams by 2050. This goal was achieved in March 2023 by OpenAI's GPT-4. This AI has a [verbal IQ of 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), speaks 23 languages, can program, and [can deceive people](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Fortunately, GPT-4 is not yet superhuman in all aspects. For example, it cannot effectively hack or write computer viruses, but it's possible that these skills are only a few innovations away. Given the current pace of AI investment, this point is rapidly approaching.

These massive and unexpected leaps in capabilities have prompted many experts to request a pause in the development of AI through an [open letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) addressed to major AI companies. The letter has been signed over 27,000 times, mostly by AI researchers and tech luminaries. A [recent survey](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in the United States shows significant support for a pause, with

more than 60% of the public in favor. Unfortunately, it appears that companies are not willing to voluntarily jeopardize their competitive positions by stopping. These AI companies are locked in a race to the bottom, where safety increasingly takes a back seat to improving capabilities. Therefore, the pause must be imposed by governments. Implementing a national pause is also challenging as countries have reasons not to be the first to pause. Therefore, an international solution is needed: a summit conference. PauseAI is calling on our governments to organize that summit conference.

For more information, please visit [PauseAI.info](http://pauseai.info).
