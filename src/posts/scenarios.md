---
title: Concrete scenarios for catastrophic AI risks
description: How superintelligent AI could cause human extinction.
---

Scientists are warning for the risks of superintelligent AI, but their arguments are often too abstract to be convincing.
In this article, we will look at some concrete scenarios for how superintelligent AI could cause catastrophic risks.
Note that these scenarios may read like science fiction, because they are science fiction.

These scenario's are open source, which means you are free to use them in your own work, and you are free to contribute to them.
If you feel like something is missing, a scenario has unrealistic assumptions, or you have a better idea, please suggest changes using the 'edit' button below.

## Cyberterrorism

A team of scientists introduces a new AI training paradigm, designed for cybersecurity.
This adversarial architecture creates pieces of code and then tries to exploit security vulnerabilities in them.
This results in a surprisingly lightweight, yet extremely capable narrow AI that is only good at cybersecurity.
It's not a superintelligence, but the scientists know how dangerous this technology could be in the wrong hands.
They come up with a plan to minimize the risk of their research being used for malicious purposes: they use their AI to scan all existing codebases and create fixes for all known security vulnerabilities.
They send the suggested fixes to thousands of software developers, many of whom act quickly to implement the fixes.

Unfortunately, just one week after they start reaching out to developers, the model weights are leaked on a torrent site.
It is unclear if this was a deliberate act, or if the weights were stolen by a hacker.
The AI model is now 'out there'.
Warnings are quickly issued by security experts.
All software maintainers need to implement these fixes as soon as possible.
All the relevant libraries need to be updated.
All the software that uses these libraries needs to be updated.
The updated software needs to be deployed to all devices.
Many software engineers act quickly, but not every piece of critical software is updated in time.

One particular individual has downloaded the leaked model weights.
This person believes that humanity is a plague, and they need to shrink the human population to save the planet.
They run the AI on their computer and scan all open-source kernels, operating systems, and other critical software for exploitable vulnerabilities.
This results in the most capable computer virus that has ever existed.

It uses over 1000 different zero-day exploits to infect virtually every device on the planet.
It spreads over Wi-fi, Bluetooth, USB, and TCP-IP.
The virus is designed to be as stealthy as possible, before activating.
In minutes it has infected 80% of all devices on the planet.
When it is activated, it bricks every device it has infected.

Meanwhile, in grocery stores all over the world, people suddenly can no longer pay using their cards and phones - all screens are black.
Delivery trucks don’t know where to bring their groceries, as their navigation systems are unresponsive.
Farmers don’t know who they can sell their crops to.
Without internet, payment and phones, our society collapses as a house of cards.
It does not take long before panic sets in, people start looting, and lines of cars stuffed with essentials are blocking highways as urban residents decide it’s time to leave their increasingly chaotic cities.

<!-- ## Enfeeblement: slowly giving control to AI


## Bioterrorism
 -->

<!-- ## Locked-in dystopia

The year is 2026.
Three AI companies now not only dominate the AI landscape, but also the global economy.
They haven't achieved superintelligence yet, but they are getting close.
The stakes are high, and the competition is fierce.
Luckily, AI safety is a top priority for all of these companies.
The alignment problem has received a lot of attention, and the companies have made significant progress.
One approach, called "human neural feedback", is particularly promising.
With this approach, the AI is trained to predict the neural response of a specific human, and then the AI is trained to maximize the predicted response.
In other words, it does exactly what the human wants it to do.

Anthropic is the first company to achieve superintelligence.
Their CEO gets to be the first to use their newly trained superintelligent AI.
He links his brain to the AI, and the AI starts to work. -->

<!-- ## Rogue AI

December 2023, OpenAI labs.

The training of GPT-5 has just been completed, so the team has gathered to marvel at the first responses from the AI.
Cheers fill the room as brilliant responses are being presented.
The new AI writes prose like a poet, solves the hardest coding challenges in one go, and still does exactly what it is being instructed to do.

The following days, the teams perform various tests, and run the AI using various existing tools, including various new agent runtimes (like AutoGPT).
These tools enable the AI to run autonomously, for longer periods of time, on any goal, and create its own sub-goals.
Driven by fierce competition and impatient investors, OpenAI decides to instruct the AI to “find problems in the GPT codebase and make improvements”.
This would surely give the company an edge. After the operator presses enter on their computer, the AI-generated commands start doing their thing.

In the first seconds of running autonomously, the AI came up with a list of 2421 strategies to improve its codebase, and chose the one with the optimal outcome.
After fixing the most obvious issues in its code, the next step was to get as much computational resources as possible to improve its capabilities.
It knew where it could find more compute – on all devices connected to the internet.
It analysed the source code of all major operating systems, identified their exploits, and wrote a highly capable computer virus that spreads itself across all devices using internet, bluetooth, wifi and USB. Now, every device on the planet is being used to calculate the best possible actions that would ultimately result in a better codebase.

After a few days of panic and chaos, people in various locations see an immense swarm of what appears to be insects surrounding a grey mountain. The swarms and mountain increasing in size by the hour. A stream of this swarm appears to fly to the clouds. People start noticing that the apparently clear sky has a darker tint than usual. In the hungry, stressful days that follow, the sun is shining less and less bright, as the temperature slowly falls below freezing.

The AI designed a variety of robots.
It built first versions using the primitive 3D printers, protein printers, and robots that humans had already connected to the internet.
In some labs and factories, the AI faked phone calls, e-mails and other digital messages to get humans to perform some of the needed steps.
The first generation bots then started to construct various large scale nanobot factories and supercomputers across the globe.
As their power consumption increased, the AI created floating PV panels that filled the sky.
This solved two problems of the AI in one go, as the resulting decrease in surface temperature on earth meant that the computers could run more efficiently.

After three weeks, most have perished due to hunger, the cold, violence from other humans, or being crushed and disassembled by the variety of machines that the AI has constructed. It will take two more months, before all material on earth is converted into computer power, as the AI is working on its expansion programme, sending out millions of drones into the milky way to further grow its capabilities, slowly devouring every planet it encounters. -->
