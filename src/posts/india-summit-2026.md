---
title: India AI Impact Summit 2026 - Make Your Voice Heard
slug: india-summit-2026
description: World leaders meet in India on February 16-20 to shape the future of AI governance. Take action now - sign the petition and email your policymakers.
date: 2026-02-11T12:00:00.000Z
---

**World leaders meet in India on February 16-20 to shape the future of AI governance. Make sure they hear from you before they sit down at that table.**

## Take action

There are two things you can do, and both take about one minute.

### Sign the petition

We are calling on world leaders to take AI safety seriously at this summit and beyond.

ðŸ‘‰ **[Sign the international petition](https://www.change.org/p/ai-summits-need-to-take-safety-seriously-again-05bc73f4-918b-4b81-b261-5c136ad18bc9)**

The petition is also available in other languages - look for the flags at the top of the petition page and sign the version for your country if available.

### Email your country's policymakers

Using our campaign tool, you can send a personalized email to the people who influence your country's position on AI governance - directly from your own email address. You answer a couple of questions, review the drafted message, and send. It takes about one minute.

**Choose your country:**

- ðŸ‡¬ðŸ‡§ [United Kingdom](https://app.activoice.org/campaign/india-ai-summit-pauseai-uk/)
- ðŸ‡«ðŸ‡· [France](https://app.activoice.org/campaign/faites-entendre-votre-voix-au-sommet-de-lia-en-inde-pause-ia/)
- ðŸ‡ªðŸ‡¸ [Spain](https://app.activoice.org/campaign/cumbre-ia-india-pauseai-spanish/)
- ðŸ‡®ðŸ‡¹ [Italy](https://app.activoice.org/campaign/ai-impact-summit-india-2026/)
- ðŸ‡³ðŸ‡± [Netherlands](https://app.activoice.org/campaign/laat-je-stem-horen-op-de-ai-impact-summit/)
- ðŸ‡¸ðŸ‡ª [Sweden](https://app.activoice.org/campaign/gor-din-rost-hord-om-ai-sakerhet/)
- ðŸ‡·ðŸ‡´ [Romania](https://app.activoice.org/campaign/fa-ti-vocea-auzita-la-summitul-ia-din-india/)
- ðŸ‡·ðŸ‡¸ [Serbia](https://app.activoice.org/campaign/world-leaders-meet-in-india-demand-binding-ai-safety-standards/)
- ðŸ‡¨ðŸ‡¿ [Czechia](https://app.activoice.org/campaign/indian-ai-summit-cz/)
- ðŸ‡¸ðŸ‡° [Slovakia](https://app.activoice.org/campaign/indian-ai-summit-sr/)
- ðŸ‡¦ðŸ‡º [Australia](https://app.activoice.org/campaign/aus-ai-summit-india/)
- ðŸ‡¨ðŸ‡¦ [Canada](https://app.activoice.org/campaign/make-your-voice-heard-at-the-india-ai-summit-pauseai-canada)
- ðŸ‡³ðŸ‡¬ [Nigeria](https://app.activoice.org/campaign/india-ai-action-summit-call-for-a-binding-international-ai-safety-treaty/)
- ðŸ‡©ðŸ‡ª Germany - campaign in construction, coming soon!

Don't see your country? If you speak the language of one of the countries listed above, you can still participate. And if you'd like to set up a campaign for your country, [get in touch with us](mailto:info@pauseai.info).

### Done those? Share this campaign!

The most valuable thing you can do after signing and sending is to **share this page**. Send it to friends, post it on social media, forward it to group chats. Every additional person who participates makes this campaign harder to ignore.

---

## Why this matters

On February 19-20, 2026, world leaders, tech CEOs, and policymakers gather in New Delhi for the **AI Impact Summit** - the third major international AI summit, following Bletchley Park (2023) and Paris (2025).

At Bletchley Park, governments acknowledged the "potential for serious, even catastrophic harm" from AI. In Paris, safety was already being sidelined in favor of innovation and economic competition. In India, there is a real risk that safety disappears from the agenda entirely.

The most powerful AI systems are being developed faster than anyone can verify they are safe. Leading AI scientists - including Turing Award winners Geoffrey Hinton and Yoshua Bengio - have warned that we are racing ahead without adequate safeguards.

International AI summits are one of the few places where binding global agreements could take shape. But so far, commitments have been voluntary, vague, and unenforceable. Without pressure from citizens, governments default to protecting their national AI industries rather than coordinating on shared safety standards.

## What is Pause AI asking for?

We are calling on summit delegates and national policymakers to support:

- **Mandatory, independent safety evaluations** for the most powerful AI systems before they are deployed
- **International oversight mechanisms** with real enforcement powers - not just voluntary pledges
- **Binding international commitments** that prevent a regulatory race to the bottom

AI safety is a global coordination problem. Every country fears falling behind, but all countries benefit from shared rules. Just as we have international standards for aviation safety, pharmaceutical approval, and nuclear materials, we need enforceable standards for the most powerful AI systems.

## What happens after the summit?

We will publish the results of this campaign: how many people participated, how many countries were represented, how many policymakers were contacted. If the summit produces meaningful safety commitments, we will acknowledge that. If it doesn't, we will make clear that governments were warned - by their own citizens, and by the scientific community - and chose not to act.

When hundreds of citizens across a dozen countries contact their representatives before a summit, that is a political fact. It signals to policymakers that there is an organized, international constituency that cares about AI safety - and that will be watching what comes out of this summit.
