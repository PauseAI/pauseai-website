---
title: PauseAI in Australia
slug: australia
description: the Australian chapter of PauseAI
---
**A message from PauseAI volunteers in Australia:**

By 2030, artificial intelligence could be fully automated, self-improving and **smarter than humans at almost everything.** This isn't science fiction—it's the assessment of leading AI companies and researchers. When this happens, every aspect of life will change forever.

**[Join our community](/join)** | [Email us](mailto:australia@pauseai.info) | [Connect on Facebook](https://www.facebook.com/groups/571590459293618) | [YouTube channel](https://www.youtube.com/channel/UCjjMieiOlSFf7jud0yhHQSg) | [Events](https://lu.ma/PauseAIAustralia)

### What risks are we facing?

Artificial Intelligence is advancing [at an astonishing rate](/urgency). Some experts like [Sam Altman](https://time.com/7205596/sam-altman-superintelligence-agi/), [Dario Amodei](https://arstechnica.com/ai/2025/01/anthropic-chief-says-ai-could-surpass-almost-all-humans-at-almost-everything-shortly-after-2027/), and [Geoffrey Hinton](https://en.wikipedia.org/wiki/Artificial_general_intelligence) warn that **AI could surpass human intelligence within the next five years**. Without international cooperation, this could result in economic chaos, war, and even [human extinction](/xrisk).

> "As general-purpose AI becomes more capable, evidence of additional risks is gradually emerging. These include risks such as large-scale labour market impacts, AI-enabled hacking or biological attacks, and society losing control over general-purpose AI."
>
> – [International AI Safety Report (2025)](https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf), co-authored by 96 experts from 30 countries, including Australia.

### Don't we want AI's benefits?

Sure. Artificial Intelligence already has the potential to be a powerful tool. If AI remains under control, it could be used to cure diseases, drive scientific breakthroughs, and spread opportunity and wellbeing. But it would be tragic to achieve these advances only to then [lose control](/ai-takeover) and suffer catastrophic losses.

New technologies have always brought change, but humans need time to adjust, safeguard, and plan for the future. For any other technology—whether aeroplanes, skyscrapers, or new medications—we insist on expertly designed safety measures before exposing the public to risks. This is not happening with AI.

AI companies are in a race, fueled by billions of dollars of investment, to build superhuman AI first. When one company succeededs, your life and that of your loved ones will become radically different, and you won't have any say in what this future holds. This isn't just a tech issue— it will affect everyone.

### What can be done?

PauseAI [proposes](/proposal) an international treaty to pause the development of smarter-than-human general AI until there is a credible plan to ensure it is safe. It is in Australia's interest to advocate for this.

> "Who will show leadership on negotiating an AI non-proliferation treaty? It is a collective responsibility and certainly one to which Australia could contribute."
>
> – Alan Finkel, Australia's Chief Scientist (2016–2020)
>
> [Sydney Morning Herald](https://www.smh.com.au/technology/the-ai-horse-has-bolted-it-s-time-for-the-nuclear-option-20230807-p5duel.html)

History shows that smaller countries can make a big difference in solving global problems. Take the 1982 ban on whale hunting and the 1987 agreement to protect the ozone layer. Australia, which used to hunt whales itself, became a leader in protecting ocean life by supporting the ban and even taking Japan to court over its whaling. Australia also helped protect the environment by quickly joining the agreement to stop using chemicals that were damaging the ozone layer. These stories show that countries like Australia can make real change happen worldwide by taking action and working with other nations.

### Aren't there more important issues?

We agree that there are many important issues facing Australia, but we won't be able to solve them in a world with uncontrolled AI. Australia should be advocating for an international treaty at the same time as it works on other issues.

### Why isn't anything being done already?

Australian politicians have looked at some of the smaller risks of AI, but not the big ones. As of the last election, [the major parties do not have a clear plan](https://www.australiansforaisafety.com.au/scorecard).

We acknowledge that not everyone agrees about the risk of an AI catastrophe. We address some of the common objections [here](/faq). We don't claim to be 100% certain, but we think the probability of very bad outcomes is more than high enough to justify a pause.

It is [psychologically difficult](/psychology-of-x-risk) to think about potential catastrophes. Many people assume that the risks are out of their control and therefore not worth worrying about. Yet, anyone can take action right now by speaking up. We think it's better to act than to simply worry.

### How can I help in Australia?

You can make a difference. Volunteers in Australia raise awareness, protest, lobby, and support the global PauseAI movement.

- [Join our community](/join)
- [Attend our next Australian online or in-person event](https://lu.ma/PauseAIAustralia)
- Sign the Australians for AI Safety [open letter](https://www.australiansforaisafety.com.au/letters)
- [Contact politicians](/writing-a-letter)
- Talk to your friends and family about AI risk
