---
title: AI Safety Summit
description: What it would take to organize a summit on AI safety.
---

AI presents very real risks to humanity, including the [risk of extinction](/xrisk).
Progress in AI capabilities is accelerating at a [frantic pace](/urgency), and we are not prepared for the consequences.
AI companies are locked in a race to the bottom, where safety is not the highest priority.
We need governments to step in and regulate AI development.
This needs to happen on an international level.
**The only way to achieve this is through a summit.**

The primary goal of PauseAI was to convince one government to organize such a summit.
Just 5 weeks after the first PauseAI protest, the UK government has announced that they will host an AI safety summit in autumn 2023.
This is amazing news, and we are very grateful to the UK government for taking this step.
However, this does not mean that we're done.

## What is a summit?

A summit is a meeting of national governments, hosted by one of them.
A summit can take many days and will be attended by many people.
Organizing it is a monumental task, and few people have the experience to do it as summits are not very common.

The goal of the Summit itself is a _treaty_, which is a formal agreement between two or more states in reference to peace, alliance, commerce, or other international relations.
In our case, the AI Safety Treaty should be an agreement between the participating states to pause AI development until the risks are better understood.

## Organizing a summit

One government will have to take the lead in organizing the summit.
This government will be the host of the summit and will be responsible for the logistics.
They need to find a suitable date and location, arrange the catering, draft the agenda, and invite the other governments.

## Examples of Summits and resulting treaties

- **Montreal Protocol** (1987): The Montreal Protocol is an international environmental treaty designed to protect the ozone layer by phasing out the production and consumption of ozone-depleting substances. It has been highly successful in reducing the use of substances like chlorofluorocarbons (CFCs) and has contributed to the gradual recovery of the ozone layer.
- **Stockholm Convention on Persistent Organic Pollutants** (2001): The Stockholm Convention is an international treaty aimed at protecting human health and the environment from persistent organic pollutants (POPs). These are toxic chemicals that persist in the environment, bioaccumulate in living organisms, and can have serious adverse effects on human health and ecosystems. Scientists raised concerns about the harmful effects of POPs, including their ability to travel long distances through air and water currents. The convention led to the banning or severe restrictions on the production and use of several POPs, including polychlorinated biphenyls (PCBs), dichlorodiphenyltrichloroethane (DDT), and dioxins.

## Suggested educational agenda

Many people will be attending the AI safety summit, and not all of them will be deeply familiar with AI safety.
They must be able to follow the discussions and make informed decisions.
Therefore, we believe it is paramount to make education on x-risk a part of the Summit.

One particularly interesting (yet unconventional) approach, is to require attendees to [learn](/learn) about AI safety before attending the summit.
Additionally, the summit itself should include a few days of education on AI safety and policy.

The following is a suggested agenda for the summit:

- **Introduction to Artificial Intelligence**. Without understanding the basics of AI, it is almost impossible to understand the risks.
  - Neural networks.
  - Large language models.
  - Market dynamics of AI
- **AI safety**. The difficulty of the alignment problem is not obvious. Understanding the core challenges of the field is necessary to understand the urgency of the situation.
  - What is a Superintelligence
  - The alignment problem
  - Instrumental convergence
  - Orthogonality thesis
- **AI safety policy**. Governing the complex field of AI safety is not easy. We need to understand the challenges and opportunities of AI safety policy.
  - International level
  - Funding AI safety research
  - Risks of AI research publications
  - Governance of open source models
- **Negotiation of the treaty**. See [our proposal](/proposal) for concrete suggestions on the contents of the treaty.
