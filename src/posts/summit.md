---
title: Why we need AI Safety Summits
description: Why we need the AI safety summit to happen, and what it should achieve.
---

AI presents numerous [risks](/risks) to humanity, including the [risk of extinction](/xrisk).
Progress in AI capabilities is accelerating at a [frantic pace](/urgency), and we are not prepared for the consequences.
AI companies are locked in a race to the bottom, where safety is not the highest priority.
We need governments to step in and prevent AI from reaching superhuman levels before we know how to make it safely.
This [pause](/proposal) needs to happen on an international level because countries are locked in a race similar to the companies.
International agreements means _treaties_, and that requires countries to meet in person and negotiate.
**The only way to achieve a true pause is through a summit.**

There have been some examples of international summits & resulting treaties that have been successful in reducing risks:

- **Montreal Protocol** (1987): The Montreal Protocol is an international environmental treaty designed to protect the ozone layer by phasing out the production and consumption of ozone-depleting substances. It has been highly successful in reducing the use of substances like chlorofluorocarbons (CFCs) and has contributed to the gradual recovery of the ozone layer.
- **Stockholm Convention on Persistent Organic Pollutants** (2001): The Stockholm Convention is an international treaty aimed at protecting human health and the environment from persistent organic pollutants (POPs). These are toxic chemicals that persist in the environment, bioaccumulate in living organisms, and can have serious adverse effects on human health and ecosystems. Scientists raised concerns about the harmful effects of POPs, including their ability to travel long distances through air and water currents. The convention led to the banning or severe restrictions on the production and use of several POPs, including polychlorinated biphenyls (PCBs), dichlorodiphenyltrichloroethane (DDT), and dioxins.

## AI Safety Summits

### 2023 UK AI Safety Summit

The primary goal of PauseAI was to convince one government to organize such a summit.
Just 5 weeks after the first PauseAI protest, the UK government [announced](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) that they would host an AI safety summit, which was held on November 1st and 2nd 2023.
The summit was relatively small (only 100 people were invited) and was held in Bletchley Park.
Although it did not lead to a binding treaty, it did lead to the ["Bletchley Declaration"](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023), which was signed by all 28 attending countries.
In this declaration, the countries acknowledged AI risks (including 'issues of control relating to alignment with human intent').
This summit also led to two follow-up summits to be announced for 2024, in Seoul and Paris.

### 2024 South Korea AI Safety Summit (May 21st, 22nd)

For months, it was unclear what the scope of this Seoul summit would be.
All that we knew, was that it was going to be a ["virtual mini summit"](https://www.bracknellnews.co.uk/news/national/23898764.ai-safety-institute-will-make-uk-global-hub-rishi-sunak-says/).
A rather unambitious way to deal with the highly alarming calls for regulation.
In April 2024, the second AI safety summit was [officially announced](https://www.gov.uk/government/news/uk-and-republic-of-korea-to-build-on-legacy-of-bletchley-park) by the UK government.
We [organized a protest on May 13th](/2024-may) to convince our ministers to attend the summit (some were [not planning on even attending](https://www.reuters.com/technology/second-global-ai-safety-summit-faces-tough-questions-lower-turnout-2024-04-29/) and initialize treaty negotiations toward a pause.

The Summit led to the following things:

1. 16 Companies (most prominent AI companies) signed the ["Frontier AI Safety Commitments"](https://www.gov.uk/government/news/historic-first-as-companies-spanning-north-america-asia-europe-and-middle-east-agree-safety-commitments-on-development-of-ai?utm_source=substack&utm_medium=email), which means these companies will publish RSPs. Previous voluntary commitments [were ignored](https://www.politico.eu/article/rishi-sunak-ai-testing-tech-ai-safety-institute/).
2. A [new statement](https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024) was signed by 27 countries.

## 2024 November San Francisco AI Safety Conference

In September, the AISI and the US government surprised us with the announcement of a new summit (or "conference") in San Francisco.
Or, more precisely, two new conferences.

On **November 20th-21st**, the first international meeting of [AI safety institutes](https://www.commerce.gov/news/press-releases/2024/09/us-secretary-commerce-raimondo-and-us-secretary-state-blinken-announce) takes place in SF, organized by the US government, aiming to "begin advancing global collaboration and knowledge sharing on AI safety."
The initial members of the International Network of AI Safety Institutes are Australia, Canada, the European Union, France, Japan, Kenya, the Republic of Korea, Singapore, the United Kingdom, and the United States.
China is notably absent from this list - even thought [China's new AI Safety Institute](https://x.com/yi_zeng/status/1831133250946838740) has recently been announced.
This very much seems like a missed opportunity, as the China-US relationship is of the utmost importance when it comes to AI Safety.

On **November 21st-22nd**, The British AISI is hosting a ["conference"](https://www.aisi.gov.uk/work/conference-on-frontier-ai-safety-frameworks) in San Francisco.
The main goal here is to "convene experts from signatory companies and from research organisations to discuss the most pressing challenges in the design and implementation of frontier AI safety frameworks."

One could argue that some safety-minded higher-ups were disappointed by the choices that France made, and decided that a true Safety Summit was needed soon.

## ~~2024~~ 2025 France AI ~~Safety~~ Action Summit

During the 2023 Bletchley summit, France opted to host the next major one in November 2024.
France postponed it to February 2025.
It was also renamed to "AI _Action_ Summit", dropping the all-important "Safety" focus.
We've been told that safety will be just one of five tracks at the summit.
It is led by AI-sceptic Anne Bouverot, who is [dismissive](https://legrandcontinent-eu.translate.goog/es/2023/12/08/la-ia-no-nos-sustituira-una-conversacion-con-anne-bouverot-yann-le-cun-y-alexandre-viros/?_x_tr_sl=es&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc) of "alarmist discourse", comparing AI with calculators and comparing AI safety concerns with Y2K concerns, being certain that "AI is not going to replace us, but rather help us".
It seems increasingly unlikely that this summit will lead to the types of international regulations that we are calling for.
