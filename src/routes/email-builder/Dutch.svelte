<p>Dear __PERSON__,</p>
<p>
	First of all, thank you very much for everything you have done for __THING__. I am emailing you
	today to bring an issue to your attention, in which I believe the Netherlands and you in
	particular can play a very important role. The issue is the existential threat of artificial
	intelligence.
</p>
<p>
	Half of AI researchers <a href="https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/"
		>believe</a
	>
	that there is a 10% or greater chance that the invention of artificial superintelligence will mean
	the end of humanity. Among AI safety scientists, this chance is
	<a
		href="https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results"
		>estimated</a
	>
	to be an average of 30%. Notable examples of individuals sounding the alarm are Prof.
	<a href="https://www.youtube.com/watch?v=Y6Sgp7y178k">Geoffrey Hinton</a>
	and Prof.
	<a href="https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/">Yoshua Bengio</a>
	, both Turing-award winners and pioneers of the deep learning methods that are currently achieving
	the most success. The existential risk of AI has been acknowledged by
	<a href="https://www.safe.ai/statement-on-ai-risk">hundreds of scientists</a>, the
	<a href="https://twitter.com/gcolbourn/status/1669104216307015680">UN</a>, the US and recently the
	<a href="https://twitter.com/EU_Commission/status/1702295053668946148">EU</a>. The latest report
	on “Generatieve AI” by Rathenau also highlights these risks.
</p>

<p>
	To make a long story short: we don't know how to align AI with the complex goals and values that
	humans have. When a superintelligent system is realised, there is a significant risk that one of
	these instances will pursue a misaligned goal without us being able to stop it. And even if such a
	superhuman AI will remain under human control, the one wielding such a power could use this to
	drastically, irreversibly change the world. Such an AI could be used to develop new technologies
	and weapons, manipulate masses of people or topple governments.
</p>

<p>
	The advancements in the AI landscape have progressed much faster than anticipated. In 2020, it was
	<a href="https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known"
		>estimated</a
	>
	that an AI would pass university entrance exams by 2050. This goal was achieved in March 2023 by the
	system GPT-4 from OpenAI. These massive, unexpected leaps have prompted many experts to request a pause
	in AI development through an open letter to major AI companies. The
	<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">letter</a>
	has been signed over 33,000 times so far, including many AI researchers and tech figures.
</p>

<p>
	Unfortunately, it seems that companies are not willing to jeopardise their competitive position by
	voluntarily halting development. A pause would need to be imposed by a government. Luckily, there
	seems to be broad support for slowing down AI development. A recent
	<a
		href="https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll"
		>poll</a
	>
	indicates that 63% of American support regulations to prevent AI companies from building superintelligent
	AI. At the national level, a pause is also challenging because countries have incentives to not fall
	behind in AI capabilities. That's why we need an international solution.
</p>

<p>
	The UK organised an AI Safety Summit on November 1st and 2nd at Bletchley Park. We hoped that
	during this summit, leaders will work towards sensible solutions that prevent the very worst of
	the risks that AI poses. The Summit did not lead to any international agreement or policy. We have
	seen proposals being written by the
	<a href="https://twitter.com/SenBlumenthal/status/1700147410880569475">US Senate</a>, and even
	among AI company CEOs there is
	<a
		href="https://www.pbs.org/newshour/politics/watch-overwhelming-consensus-for-artificial-intelligence-regulation-musk-says-after-senate-tech-meeting"
		>“overwhelming consensus”</a
	>
	that regulation is needed. Unfortunately,
	<a href="https://twitter.com/DanielColson6/status/1704976418596352342">none</a>
	of the existing proposals would do anything to slow down or prevent a superintelligent AI from being
	created. I am afraid that lobbying efforts by AI companies to keep regulation at a minimum are turning
	out to be highly effective.
</p>

<p>__ACTION__</p>

<p>Best regards,</p>

<p>__YOUR NAME__</p>
